{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ce6d66f",
   "metadata": {},
   "source": [
    "## Imports and Configuration\n",
    "\n",
    "This notebook builds an image classifier that recognizes **cats**, **dogs**, and an **unknown** category for anything that is not a cat or dog.\n",
    "\n",
    "This section sets up the notebook by importing the required libraries and establishing the base configuration used throughout the workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4ac0c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import shutil\n",
    "import tarfile\n",
    "import zipfile\n",
    "from math import ceil\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67cff60",
   "metadata": {},
   "source": [
    "## Combined Pool Paths and Folder Detection\n",
    "\n",
    "This section detects the main project folder by searching upward until it finds the `Datasets` directory, then defines the paths needed to build the **combined cats and dogs pool**.\n",
    "\n",
    "It sets up the extracted dataset locations for **freeCodeCamp** and **Microsoft**, creates the `combined_pool/cats` and `combined_pool/dogs` output folders, and prints a readable summary to confirm everything was found correctly.\n",
    "\n",
    "The combined pool is used to create the **training** and **evaluation** splits later in the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9abb21cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project folder detected: C:\\Users\\223023795\\Desktop\\Cat and Dog Classifier\n",
      "Found extracted datasets folder: True  ->  C:\\Users\\223023795\\Desktop\\Cat and Dog Classifier\\Datasets\\Extracted\n",
      "Extracted dataset folders available: coco_annotations, coco_val2017, freecodecamp, microsoft, oxford, places365_val_256\n",
      "freeCodeCamp extracted folder found: True  ->  C:\\Users\\223023795\\Desktop\\Cat and Dog Classifier\\Datasets\\Extracted\\freecodecamp\n",
      "Microsoft extracted folder found:   True  ->  C:\\Users\\223023795\\Desktop\\Cat and Dog Classifier\\Datasets\\Extracted\\microsoft\n",
      "Combined pool output folder ready:  True  ->  C:\\Users\\223023795\\Desktop\\Cat and Dog Classifier\\Datasets\\Prepared\\combined_pool\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Start from the notebook's current working directory.\n",
    "starting_directory = Path.cwd().resolve()\n",
    "\n",
    "# Walk upward until the folder that contains \"Datasets\" is found.\n",
    "base_project_directory = None\n",
    "for candidate_directory in [starting_directory] + list(starting_directory.parents):\n",
    "    if (candidate_directory / \"Datasets\").exists():\n",
    "        base_project_directory = candidate_directory\n",
    "        break\n",
    "\n",
    "# Stop early if the expected project structure is not found.\n",
    "if base_project_directory is None:\n",
    "    raise RuntimeError(f\"I could not find a 'Datasets' folder when searching upward from: {starting_directory}\")\n",
    "\n",
    "datasets_directory = base_project_directory / \"Datasets\"\n",
    "extracted_datasets_directory = datasets_directory / \"Extracted\"\n",
    "prepared_datasets_directory = datasets_directory / \"Prepared\"\n",
    "\n",
    "# Define where the combined pool will be written.\n",
    "combined_pool_directory = prepared_datasets_directory / \"combined_pool\"\n",
    "combined_pool_cats_directory = combined_pool_directory / \"cats\"\n",
    "combined_pool_dogs_directory = combined_pool_directory / \"dogs\"\n",
    "\n",
    "# Create the combined pool folders if they do not exist yet.\n",
    "combined_pool_cats_directory.mkdir(parents=True, exist_ok=True)\n",
    "combined_pool_dogs_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define the extracted dataset folders that feed into the combined pool.\n",
    "extracted_freecodecamp_directory = extracted_datasets_directory / \"freecodecamp\"\n",
    "extracted_microsoft_directory = extracted_datasets_directory / \"microsoft\"\n",
    "\n",
    "# Print a quick, readable status summary so you can confirm paths are correct.\n",
    "print(f\"Project folder detected: {base_project_directory}\")\n",
    "print(f\"Found extracted datasets folder: {extracted_datasets_directory.exists()}  ->  {extracted_datasets_directory}\")\n",
    "\n",
    "if extracted_datasets_directory.exists():\n",
    "    extracted_subfolder_names = sorted([path.name for path in extracted_datasets_directory.iterdir() if path.is_dir()])\n",
    "    print(\"Extracted dataset folders available:\", \", \".join(extracted_subfolder_names) if extracted_subfolder_names else \"(none)\")\n",
    "\n",
    "print(f\"freeCodeCamp extracted folder found: {extracted_freecodecamp_directory.exists()}  ->  {extracted_freecodecamp_directory}\")\n",
    "print(f\"Microsoft extracted folder found:   {extracted_microsoft_directory.exists()}  ->  {extracted_microsoft_directory}\")\n",
    "print(f\"Combined pool output folder ready:  {combined_pool_directory.exists()}  ->  {combined_pool_directory}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81b1896",
   "metadata": {},
   "source": [
    "## Build Combined Cats and Dogs Pool\n",
    "\n",
    "This section combines cat and dog images from the extracted **freeCodeCamp** and **Microsoft** datasets into a single pooled folder structure:\n",
    "\n",
    "- `combined_pool/cats`\n",
    "- `combined_pool/dogs`\n",
    "\n",
    "It searches the extracted folders for image files, skips corrupted files by decoding them with TensorFlow, then copies the readable images into the combined pool using unique filenames to avoid collisions. A short summary is printed showing how many files were copied and skipped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3afac8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined pool cats copied: 13427\n",
      "Combined pool dogs copied: 13397\n",
      "Skipped unreadable cats: 73\n",
      "Skipped unreadable dogs: 103\n"
     ]
    }
   ],
   "source": [
    "allowed_image_extensions = (\".jpg\", \".jpeg\", \".png\")\n",
    "skip_unreadable_images = True\n",
    "random_seed = 42\n",
    "\n",
    "\n",
    "def list_image_files_recursively(root_directory: Path) -> list[Path]:\n",
    "    # Collect all image files under a directory.\n",
    "    return [\n",
    "        file_path\n",
    "        for file_path in root_directory.rglob(\"*\")\n",
    "        if file_path.is_file() and file_path.suffix.lower() in allowed_image_extensions\n",
    "    ]\n",
    "\n",
    "\n",
    "def is_image_file_readable(image_file_path: Path) -> bool:\n",
    "    # Try decoding the image with TensorFlow to catch corrupted files.\n",
    "    try:\n",
    "        image_bytes = tf.io.read_file(str(image_file_path))\n",
    "        file_suffix = image_file_path.suffix.lower()\n",
    "\n",
    "        if file_suffix in (\".jpg\", \".jpeg\"):\n",
    "            tf.io.decode_jpeg(image_bytes, channels=3)\n",
    "            return True\n",
    "\n",
    "        if file_suffix == \".png\":\n",
    "            tf.io.decode_png(image_bytes, channels=3)\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def clear_directory_contents(directory_path: Path):\n",
    "    # Remove everything inside the directory, keep the directory itself.\n",
    "    if not directory_path.exists():\n",
    "        return\n",
    "\n",
    "    for child_path in directory_path.iterdir():\n",
    "        if child_path.is_dir():\n",
    "            shutil.rmtree(child_path)\n",
    "        else:\n",
    "            child_path.unlink()\n",
    "\n",
    "\n",
    "def find_first_existing_directory(candidate_directories: list[Path]) -> Path | None:\n",
    "    # Return the first directory that exists from a list of candidates.\n",
    "    for directory_path in candidate_directories:\n",
    "        if directory_path.exists() and directory_path.is_dir():\n",
    "            return directory_path\n",
    "    return None\n",
    "\n",
    "\n",
    "def resolve_freecodecamp_cats_dogs_directories() -> tuple[Path, Path]:\n",
    "    # Find cats and dogs folders inside the extracted freeCodeCamp directory.\n",
    "    candidate_cats_directories = [\n",
    "        extracted_freecodecamp_directory / \"cats\",\n",
    "        extracted_freecodecamp_directory / \"Cats\",\n",
    "        extracted_freecodecamp_directory / \"cat\",\n",
    "        extracted_freecodecamp_directory / \"Cat\",\n",
    "    ]\n",
    "    candidate_dogs_directories = [\n",
    "        extracted_freecodecamp_directory / \"dogs\",\n",
    "        extracted_freecodecamp_directory / \"Dogs\",\n",
    "        extracted_freecodecamp_directory / \"dog\",\n",
    "        extracted_freecodecamp_directory / \"Dog\",\n",
    "    ]\n",
    "\n",
    "    cats_directory = find_first_existing_directory(candidate_cats_directories)\n",
    "    dogs_directory = find_first_existing_directory(candidate_dogs_directories)\n",
    "\n",
    "    if cats_directory and dogs_directory:\n",
    "        return cats_directory, dogs_directory\n",
    "\n",
    "    all_directories = [path for path in extracted_freecodecamp_directory.rglob(\"*\") if path.is_dir()]\n",
    "    cats_directory = next((path for path in all_directories if path.name.lower() in {\"cats\", \"cat\"}), None)\n",
    "    dogs_directory = next((path for path in all_directories if path.name.lower() in {\"dogs\", \"dog\"}), None)\n",
    "\n",
    "    if not cats_directory or not dogs_directory:\n",
    "        raise RuntimeError(\"Could not locate freeCodeCamp cats and dogs directories after extraction.\")\n",
    "\n",
    "    return cats_directory, dogs_directory\n",
    "\n",
    "\n",
    "def resolve_microsoft_cats_dogs_directories() -> tuple[Path, Path]:\n",
    "    # Find PetImages/Cat and PetImages/Dog inside the extracted Microsoft dataset.\n",
    "    pet_images_directory = find_first_existing_directory(\n",
    "        [\n",
    "            extracted_microsoft_directory / \"PetImages\",\n",
    "            extracted_microsoft_directory / \"kagglecatsanddogs_5340\" / \"PetImages\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if not pet_images_directory:\n",
    "        pet_images_directory = next(\n",
    "            (path for path in extracted_microsoft_directory.rglob(\"PetImages\") if path.is_dir()),\n",
    "            None,\n",
    "        )\n",
    "\n",
    "    if not pet_images_directory:\n",
    "        raise RuntimeError(\"Could not locate Microsoft 'PetImages' directory after extraction.\")\n",
    "\n",
    "    cats_directory = pet_images_directory / \"Cat\"\n",
    "    dogs_directory = pet_images_directory / \"Dog\"\n",
    "\n",
    "    if not cats_directory.exists() or not dogs_directory.exists():\n",
    "        raise RuntimeError(\"Could not locate Microsoft Cat and Dog folders inside PetImages.\")\n",
    "\n",
    "    return cats_directory, dogs_directory\n",
    "\n",
    "\n",
    "def copy_images_into_pool(\n",
    "    source_image_paths: list[Path],\n",
    "    destination_directory: Path,\n",
    "    filename_prefix: str,\n",
    "    random_number_generator: random.Random,\n",
    ") -> tuple[int, int]:\n",
    "    # Copy images into the pool using unique names, optionally skipping unreadable files.\n",
    "    destination_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    copied_count = 0\n",
    "    skipped_count = 0\n",
    "\n",
    "    for image_file_path in source_image_paths:\n",
    "        if skip_unreadable_images and not is_image_file_readable(image_file_path):\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "\n",
    "        unique_suffix = f\"{random_number_generator.getrandbits(64):016x}\"\n",
    "        destination_file_name = f\"{filename_prefix}_{unique_suffix}{image_file_path.suffix.lower()}\"\n",
    "        destination_file_path = destination_directory / destination_file_name\n",
    "\n",
    "        shutil.copy2(image_file_path, destination_file_path)\n",
    "        copied_count += 1\n",
    "\n",
    "    return copied_count, skipped_count\n",
    "\n",
    "\n",
    "def rebuild_cat_dog_combined_pool():\n",
    "    # Build combined_pool/cats and combined_pool/dogs from freeCodeCamp and Microsoft extracts.\n",
    "    random_number_generator = random.Random(random_seed)\n",
    "\n",
    "    clear_directory_contents(combined_pool_cats_directory)\n",
    "    clear_directory_contents(combined_pool_dogs_directory)\n",
    "\n",
    "    freecodecamp_cats_directory, freecodecamp_dogs_directory = resolve_freecodecamp_cats_dogs_directories()\n",
    "    microsoft_cats_directory, microsoft_dogs_directory = resolve_microsoft_cats_dogs_directories()\n",
    "\n",
    "    freecodecamp_cat_images = list_image_files_recursively(freecodecamp_cats_directory)\n",
    "    freecodecamp_dog_images = list_image_files_recursively(freecodecamp_dogs_directory)\n",
    "\n",
    "    microsoft_cat_images = list_image_files_recursively(microsoft_cats_directory)\n",
    "    microsoft_dog_images = list_image_files_recursively(microsoft_dogs_directory)\n",
    "\n",
    "    freecodecamp_cat_copied, freecodecamp_cat_skipped = copy_images_into_pool(\n",
    "        source_image_paths=freecodecamp_cat_images,\n",
    "        destination_directory=combined_pool_cats_directory,\n",
    "        filename_prefix=\"freecodecamp_cat\",\n",
    "        random_number_generator=random_number_generator,\n",
    "    )\n",
    "    freecodecamp_dog_copied, freecodecamp_dog_skipped = copy_images_into_pool(\n",
    "        source_image_paths=freecodecamp_dog_images,\n",
    "        destination_directory=combined_pool_dogs_directory,\n",
    "        filename_prefix=\"freecodecamp_dog\",\n",
    "        random_number_generator=random_number_generator,\n",
    "    )\n",
    "\n",
    "    microsoft_cat_copied, microsoft_cat_skipped = copy_images_into_pool(\n",
    "        source_image_paths=microsoft_cat_images,\n",
    "        destination_directory=combined_pool_cats_directory,\n",
    "        filename_prefix=\"microsoft_cat\",\n",
    "        random_number_generator=random_number_generator,\n",
    "    )\n",
    "    microsoft_dog_copied, microsoft_dog_skipped = copy_images_into_pool(\n",
    "        source_image_paths=microsoft_dog_images,\n",
    "        destination_directory=combined_pool_dogs_directory,\n",
    "        filename_prefix=\"microsoft_dog\",\n",
    "        random_number_generator=random_number_generator,\n",
    "    )\n",
    "\n",
    "    print(\"Combined pool cats copied:\", freecodecamp_cat_copied + microsoft_cat_copied)\n",
    "    print(\"Combined pool dogs copied:\", freecodecamp_dog_copied + microsoft_dog_copied)\n",
    "    print(\"Skipped unreadable cats:\", freecodecamp_cat_skipped + microsoft_cat_skipped)\n",
    "    print(\"Skipped unreadable dogs:\", freecodecamp_dog_skipped + microsoft_dog_skipped)\n",
    "\n",
    "\n",
    "rebuild_cat_dog_combined_pool()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbf78bb",
   "metadata": {},
   "source": [
    "## Build Unknown Pool and Unknown Test Sets\n",
    "\n",
    "This section prepares the **Unknown** class in two ways:\n",
    "\n",
    "- **Places365** is split into:\n",
    "  - an **unknown pool** saved in `combined_pool/unknown` (used later for training and evaluation splits), and\n",
    "  - a **Places-only unknown test set** saved in `Datasets/Test/unknown_test/unknown_places`.\n",
    "\n",
    "- **COCO (val2017)** is used to build a separate **COCO-only unknown test set** saved in `Datasets/Test/unknown_test/unknown_coco`, filtering out any images that contain animals (including cats and dogs) using the COCO annotations file.\n",
    "\n",
    "All copied images are checked for readability by decoding them with TensorFlow, unreadable files are skipped, and the cell prints a summary of what was copied and skipped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1975806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Places365 unknown results\n",
      "  Total images found: 36500\n",
      "  Skipped unreadable: 0\n",
      "  Copied to test (unknown_places): 3650\n",
      "  Copied to pool (combined_pool/unknown): 32850\n",
      "\n",
      "COCO unknown test results\n",
      "  Images checked: 5000\n",
      "  Excluded (animal present): 1016\n",
      "  Missing files skipped: 0\n",
      "  Skipped unreadable: 0\n",
      "  Copied to test (unknown_coco): 3984\n"
     ]
    }
   ],
   "source": [
    "unknown_places_test_ratio = 0.10\n",
    "\n",
    "test_datasets_directory = datasets_directory / \"Test\"\n",
    "unknown_test_directory = test_datasets_directory / \"unknown_test\"\n",
    "unknown_places_test_directory = unknown_test_directory / \"unknown_places\"\n",
    "unknown_coco_test_directory = unknown_test_directory / \"unknown_coco\"\n",
    "\n",
    "# Confirm the expected test folders exist.\n",
    "if not unknown_places_test_directory.exists():\n",
    "    raise RuntimeError(f\"Missing folder: {unknown_places_test_directory}\")\n",
    "\n",
    "if not unknown_coco_test_directory.exists():\n",
    "    raise RuntimeError(f\"Missing folder: {unknown_coco_test_directory}\")\n",
    "\n",
    "# Source folders from extracted datasets.\n",
    "extracted_places365_directory = extracted_datasets_directory / \"places365_val_256\"\n",
    "extracted_coco_validation_images_directory = extracted_datasets_directory / \"coco_val2017\"\n",
    "extracted_coco_annotations_directory = extracted_datasets_directory / \"coco_annotations\"\n",
    "\n",
    "# Unknown pool used later for training and evaluation splits.\n",
    "combined_pool_unknown_directory = combined_pool_directory / \"unknown\"\n",
    "combined_pool_unknown_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def find_coco_validation_images_directory() -> Path:\n",
    "    candidate_val2017_directory = extracted_coco_validation_images_directory / \"val2017\"\n",
    "    if candidate_val2017_directory.exists():\n",
    "        return candidate_val2017_directory\n",
    "\n",
    "    discovered_val2017_directory = next(\n",
    "        (path for path in extracted_coco_validation_images_directory.rglob(\"val2017\") if path.is_dir()),\n",
    "        None,\n",
    "    )\n",
    "    if not discovered_val2017_directory:\n",
    "        raise RuntimeError(\"Could not locate COCO val2017 images directory after extraction.\")\n",
    "    return discovered_val2017_directory\n",
    "\n",
    "\n",
    "def find_coco_instances_validation_json() -> Path:\n",
    "    candidate_json_path = extracted_coco_annotations_directory / \"annotations\" / \"instances_val2017.json\"\n",
    "    if candidate_json_path.exists():\n",
    "        return candidate_json_path\n",
    "\n",
    "    discovered_json_path = next(\n",
    "        (path for path in extracted_coco_annotations_directory.rglob(\"instances_val2017.json\") if path.is_file()),\n",
    "        None,\n",
    "    )\n",
    "    if not discovered_json_path:\n",
    "        raise RuntimeError(\"Could not locate instances_val2017.json after extracting COCO annotations.\")\n",
    "    return discovered_json_path\n",
    "\n",
    "\n",
    "def rebuild_unknown_from_places():\n",
    "    # Split Places365 into: (1) training/eval unknown pool, (2) Places-only unknown test set.\n",
    "    random_number_generator = random.Random(random_seed)\n",
    "\n",
    "    clear_directory_contents(combined_pool_unknown_directory)\n",
    "    clear_directory_contents(unknown_places_test_directory)\n",
    "\n",
    "    places_image_paths = list_image_files_recursively(extracted_places365_directory)\n",
    "    if not places_image_paths:\n",
    "        raise RuntimeError(\"No Places365 images were found after extraction.\")\n",
    "\n",
    "    random_number_generator.shuffle(places_image_paths)\n",
    "\n",
    "    places_test_image_count = ceil(len(places_image_paths) * unknown_places_test_ratio)\n",
    "    places_test_image_paths = places_image_paths[:places_test_image_count]\n",
    "    places_pool_image_paths = places_image_paths[places_test_image_count:]\n",
    "\n",
    "    test_copied_count, test_skipped_count = copy_images_into_pool(\n",
    "        source_image_paths=places_test_image_paths,\n",
    "        destination_directory=unknown_places_test_directory,\n",
    "        filename_prefix=\"places_test_unknown\",\n",
    "        random_number_generator=random_number_generator,\n",
    "    )\n",
    "    pool_copied_count, pool_skipped_count = copy_images_into_pool(\n",
    "        source_image_paths=places_pool_image_paths,\n",
    "        destination_directory=combined_pool_unknown_directory,\n",
    "        filename_prefix=\"places_pool_unknown\",\n",
    "        random_number_generator=random_number_generator,\n",
    "    )\n",
    "\n",
    "    total_skipped_count = test_skipped_count + pool_skipped_count\n",
    "\n",
    "    print(\"Places365 unknown results\")\n",
    "    print(f\"  Total images found: {len(places_image_paths)}\")\n",
    "    print(f\"  Skipped unreadable: {total_skipped_count}\")\n",
    "    print(f\"  Copied to test (unknown_places): {test_copied_count}\")\n",
    "    print(f\"  Copied to pool (combined_pool/unknown): {pool_copied_count}\")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "def rebuild_unknown_coco_test_filtered():\n",
    "    # Build a COCO-only unknown test set by excluding images that contain animals (including cats and dogs).\n",
    "    random_number_generator = random.Random(random_seed)\n",
    "\n",
    "    clear_directory_contents(unknown_coco_test_directory)\n",
    "\n",
    "    coco_images_directory = find_coco_validation_images_directory()\n",
    "    coco_instances_json_path = find_coco_instances_validation_json()\n",
    "\n",
    "    with open(coco_instances_json_path, \"r\", encoding=\"utf-8\") as json_file:\n",
    "        coco_instances = json.load(json_file)\n",
    "\n",
    "    excluded_category_ids = {\n",
    "        16,  # bird\n",
    "        17,  # cat\n",
    "        18,  # dog\n",
    "        19,  # horse\n",
    "        20,  # sheep\n",
    "        21,  # cow\n",
    "        22,  # elephant\n",
    "        23,  # bear\n",
    "        24,  # zebra\n",
    "        25,  # giraffe\n",
    "    }\n",
    "\n",
    "    annotations_by_image_id: dict[int, set[int]] = {}\n",
    "    for annotation in coco_instances.get(\"annotations\", []):\n",
    "        image_id = int(annotation[\"image_id\"])\n",
    "        category_id = int(annotation[\"category_id\"])\n",
    "        if image_id not in annotations_by_image_id:\n",
    "            annotations_by_image_id[image_id] = set()\n",
    "        annotations_by_image_id[image_id].add(category_id)\n",
    "\n",
    "    copied_count = 0\n",
    "    skipped_unreadable_count = 0\n",
    "    missing_file_count = 0\n",
    "    excluded_animal_count = 0\n",
    "    total_checked_count = 0\n",
    "\n",
    "    for image_item in coco_instances.get(\"images\", []):\n",
    "        image_id = int(image_item[\"id\"])\n",
    "        file_name = image_item[\"file_name\"]\n",
    "        image_path = coco_images_directory / file_name\n",
    "\n",
    "        if not image_path.exists():\n",
    "            missing_file_count += 1\n",
    "            continue\n",
    "\n",
    "        total_checked_count += 1\n",
    "\n",
    "        category_ids_in_image = annotations_by_image_id.get(image_id, set())\n",
    "        if category_ids_in_image.intersection(excluded_category_ids):\n",
    "            excluded_animal_count += 1\n",
    "            continue\n",
    "\n",
    "        if skip_unreadable_images and not is_image_file_readable(image_path):\n",
    "            skipped_unreadable_count += 1\n",
    "            continue\n",
    "\n",
    "        unique_suffix = f\"{random_number_generator.getrandbits(64):016x}\"\n",
    "        destination_file_name = f\"coco_test_unknown_{unique_suffix}{image_path.suffix.lower()}\"\n",
    "        destination_file_path = unknown_coco_test_directory / destination_file_name\n",
    "        shutil.copy2(image_path, destination_file_path)\n",
    "        copied_count += 1\n",
    "\n",
    "    print(\"COCO unknown test results\")\n",
    "    print(f\"  Images checked: {total_checked_count}\")\n",
    "    print(f\"  Excluded (animal present): {excluded_animal_count}\")\n",
    "    print(f\"  Missing files skipped: {missing_file_count}\")\n",
    "    print(f\"  Skipped unreadable: {skipped_unreadable_count}\")\n",
    "    print(f\"  Copied to test (unknown_coco): {copied_count}\")\n",
    "\n",
    "\n",
    "rebuild_unknown_from_places()\n",
    "rebuild_unknown_coco_test_filtered()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296d4836",
   "metadata": {},
   "source": [
    "## Build Oxford Cats and Dogs Test Set\n",
    "\n",
    "This section creates a **cats vs dogs** test set using **all extracted Oxford images**.\n",
    "\n",
    "It reads every image in the Oxford `images` folder, infers whether it is a cat or dog from the breed name in the filename, then copies the files into:\n",
    "\n",
    "- `Datasets/Test/oxford_test/cats`\n",
    "- `Datasets/Test/oxford_test/dogs`\n",
    "\n",
    "Unreadable images are skipped using the TensorFlow decoding check, and a short summary is printed at the end.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41bc6bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oxford cats and dogs test results\n",
      "  Total images found: 7390\n",
      "  Unrecognized filenames skipped: 0\n",
      "  Skipped unreadable: 0\n",
      "  Copied to test (oxford_test/cats): 2400\n",
      "  Copied to test (oxford_test/dogs): 4990\n"
     ]
    }
   ],
   "source": [
    "# Oxford test output folders (must already exist).\n",
    "test_datasets_directory = datasets_directory / \"Test\"\n",
    "oxford_test_directory = test_datasets_directory / \"oxford_test\"\n",
    "oxford_test_cats_directory = oxford_test_directory / \"cats\"\n",
    "oxford_test_dogs_directory = oxford_test_directory / \"dogs\"\n",
    "\n",
    "if not oxford_test_cats_directory.exists():\n",
    "    raise RuntimeError(f\"Missing folder: {oxford_test_cats_directory}\")\n",
    "\n",
    "if not oxford_test_dogs_directory.exists():\n",
    "    raise RuntimeError(f\"Missing folder: {oxford_test_dogs_directory}\")\n",
    "\n",
    "# Oxford extracted dataset location.\n",
    "extracted_oxford_directory = extracted_datasets_directory / \"oxford\"\n",
    "\n",
    "\n",
    "def find_oxford_images_directory() -> Path:\n",
    "    # Locate the Oxford images folder, even if extraction created nested folders.\n",
    "    candidate_images_directory = extracted_oxford_directory / \"images\"\n",
    "    if candidate_images_directory.exists():\n",
    "        return candidate_images_directory\n",
    "\n",
    "    discovered_images_directory = next(\n",
    "        (path for path in extracted_oxford_directory.rglob(\"images\") if path.is_dir()),\n",
    "        None,\n",
    "    )\n",
    "    if not discovered_images_directory:\n",
    "        raise RuntimeError(\"Could not locate Oxford images directory after extraction.\")\n",
    "    return discovered_images_directory\n",
    "\n",
    "\n",
    "def extract_oxford_breed_name_from_filename(image_file_path: Path) -> str | None:\n",
    "    # Oxford filename format is usually BreedName_123.jpg, breed can contain underscores.\n",
    "    file_stem = image_file_path.stem\n",
    "    stem_parts = file_stem.split(\"_\")\n",
    "    if len(stem_parts) < 2:\n",
    "        return None\n",
    "\n",
    "    last_part = stem_parts[-1]\n",
    "    if not last_part.isdigit():\n",
    "        return None\n",
    "\n",
    "    breed_name = \"_\".join(stem_parts[:-1]).strip()\n",
    "    return breed_name if breed_name else None\n",
    "\n",
    "\n",
    "def rebuild_oxford_all_images_test_set():\n",
    "    random_number_generator = random.Random(random_seed)\n",
    "\n",
    "    # These are the 12 cat breeds in Oxford-IIIT Pet. Everything else is a dog breed.\n",
    "    cat_breed_names = {\n",
    "        \"abyssinian\",\n",
    "        \"bengal\",\n",
    "        \"birman\",\n",
    "        \"bombay\",\n",
    "        \"british_shorthair\",\n",
    "        \"egyptian_mau\",\n",
    "        \"maine_coon\",\n",
    "        \"persian\",\n",
    "        \"ragdoll\",\n",
    "        \"russian_blue\",\n",
    "        \"siamese\",\n",
    "        \"sphynx\",\n",
    "    }\n",
    "\n",
    "    clear_directory_contents(oxford_test_cats_directory)\n",
    "    clear_directory_contents(oxford_test_dogs_directory)\n",
    "\n",
    "    oxford_images_directory = find_oxford_images_directory()\n",
    "    oxford_image_paths = list_image_files_recursively(oxford_images_directory)\n",
    "    if not oxford_image_paths:\n",
    "        raise RuntimeError(\"No Oxford images were found after extraction.\")\n",
    "\n",
    "    cat_image_paths: list[Path] = []\n",
    "    dog_image_paths: list[Path] = []\n",
    "    unrecognized_filename_count = 0\n",
    "\n",
    "    for image_file_path in oxford_image_paths:\n",
    "        breed_name = extract_oxford_breed_name_from_filename(image_file_path)\n",
    "        if not breed_name:\n",
    "            unrecognized_filename_count += 1\n",
    "            continue\n",
    "\n",
    "        if breed_name.lower() in cat_breed_names:\n",
    "            cat_image_paths.append(image_file_path)\n",
    "        else:\n",
    "            dog_image_paths.append(image_file_path)\n",
    "\n",
    "    cat_copied_count, cat_skipped_unreadable_count = copy_images_into_pool(\n",
    "        source_image_paths=cat_image_paths,\n",
    "        destination_directory=oxford_test_cats_directory,\n",
    "        filename_prefix=\"oxford_test_cat\",\n",
    "        random_number_generator=random_number_generator,\n",
    "    )\n",
    "    dog_copied_count, dog_skipped_unreadable_count = copy_images_into_pool(\n",
    "        source_image_paths=dog_image_paths,\n",
    "        destination_directory=oxford_test_dogs_directory,\n",
    "        filename_prefix=\"oxford_test_dog\",\n",
    "        random_number_generator=random_number_generator,\n",
    "    )\n",
    "\n",
    "    total_skipped_unreadable_count = cat_skipped_unreadable_count + dog_skipped_unreadable_count\n",
    "\n",
    "    print(\"Oxford cats and dogs test results\")\n",
    "    print(f\"  Total images found: {len(oxford_image_paths)}\")\n",
    "    print(f\"  Unrecognized filenames skipped: {unrecognized_filename_count}\")\n",
    "    print(f\"  Skipped unreadable: {total_skipped_unreadable_count}\")\n",
    "    print(f\"  Copied to test (oxford_test/cats): {cat_copied_count}\")\n",
    "    print(f\"  Copied to test (oxford_test/dogs): {dog_copied_count}\")\n",
    "\n",
    "\n",
    "rebuild_oxford_all_images_test_set()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da8534c",
   "metadata": {},
   "source": [
    "## Create Train and Validation Splits\n",
    "\n",
    "This section creates the **training** and **validation** datasets from the `combined_pool` folders.\n",
    "\n",
    "It shuffles each class (`cats`, `dogs`, `unknown`) in a reproducible way, applies the split ratio (`training_split_ratio`), then copies the images into:\n",
    "\n",
    "- `Datasets/Splits/train_split/<class>`\n",
    "- `Datasets/Splits/validation_split/<class>`\n",
    "\n",
    "Unreadable images are skipped using the TensorFlow decoding check, and a summary of copied and skipped files is printed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59833bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and validation split results\n",
      "  Training split ratio: 0.8\n",
      "  Cats, total readable: 13427\n",
      "  Skipped unreadable: 0\n",
      "  Copied to train (cats): 10741\n",
      "  Copied to validation (cats): 2686\n",
      "  Dogs, total readable: 13397\n",
      "  Skipped unreadable: 0\n",
      "  Copied to train (dogs): 10717\n",
      "  Copied to validation (dogs): 2680\n",
      "  Unknown, total readable: 32850\n",
      "  Skipped unreadable: 0\n",
      "  Copied to train (unknown): 26280\n",
      "  Copied to validation (unknown): 6570\n",
      "\n",
      "Train split folder: C:\\Users\\223023795\\Desktop\\Cat and Dog Classifier\\Datasets\\Splits\\train_split\n",
      "Validation split folder: C:\\Users\\223023795\\Desktop\\Cat and Dog Classifier\\Datasets\\Splits\\validation_split\n"
     ]
    }
   ],
   "source": [
    "training_split_ratio = 0.80\n",
    "\n",
    "splits_directory = datasets_directory / \"Splits\"\n",
    "\n",
    "train_split_directory = splits_directory / \"train_split\"\n",
    "validation_split_directory = splits_directory / \"validation_split\"\n",
    "\n",
    "train_split_cats_directory = train_split_directory / \"cats\"\n",
    "train_split_dogs_directory = train_split_directory / \"dogs\"\n",
    "train_split_unknown_directory = train_split_directory / \"unknown\"\n",
    "\n",
    "validation_split_cats_directory = validation_split_directory / \"cats\"\n",
    "validation_split_dogs_directory = validation_split_directory / \"dogs\"\n",
    "validation_split_unknown_directory = validation_split_directory / \"unknown\"\n",
    "\n",
    "train_split_cats_directory.mkdir(parents=True, exist_ok=True)\n",
    "train_split_dogs_directory.mkdir(parents=True, exist_ok=True)\n",
    "train_split_unknown_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "validation_split_cats_directory.mkdir(parents=True, exist_ok=True)\n",
    "validation_split_dogs_directory.mkdir(parents=True, exist_ok=True)\n",
    "validation_split_unknown_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def split_class_directory_into_train_and_validation(\n",
    "    class_name: str,\n",
    "    combined_pool_class_directory: Path,\n",
    "    train_split_class_directory: Path,\n",
    "    validation_split_class_directory: Path,\n",
    ") -> tuple[int, int, int, int]:\n",
    "    # Deterministic shuffle per class, so the split is reproducible.\n",
    "    random_number_generator = random.Random(f\"{random_seed}_{class_name}\")\n",
    "\n",
    "    clear_directory_contents(train_split_class_directory)\n",
    "    clear_directory_contents(validation_split_class_directory)\n",
    "\n",
    "    class_image_paths = list_image_files_recursively(combined_pool_class_directory)\n",
    "    if not class_image_paths:\n",
    "        raise RuntimeError(f\"No images found in combined pool for class: {class_name}\")\n",
    "\n",
    "    unreadable_skipped_count = 0\n",
    "    readable_image_paths: list[Path] = []\n",
    "\n",
    "    # Filter out corrupted images before splitting.\n",
    "    for image_path in class_image_paths:\n",
    "        if skip_unreadable_images and not is_image_file_readable(image_path):\n",
    "            unreadable_skipped_count += 1\n",
    "            continue\n",
    "        readable_image_paths.append(image_path)\n",
    "\n",
    "    if not readable_image_paths:\n",
    "        raise RuntimeError(f\"All images were unreadable in combined pool for class: {class_name}\")\n",
    "\n",
    "    random_number_generator.shuffle(readable_image_paths)\n",
    "\n",
    "    train_image_count = int(len(readable_image_paths) * training_split_ratio)\n",
    "    train_image_paths = readable_image_paths[:train_image_count]\n",
    "    validation_image_paths = readable_image_paths[train_image_count:]\n",
    "\n",
    "    for image_path in train_image_paths:\n",
    "        shutil.copy2(image_path, train_split_class_directory / image_path.name)\n",
    "\n",
    "    for image_path in validation_image_paths:\n",
    "        shutil.copy2(image_path, validation_split_class_directory / image_path.name)\n",
    "\n",
    "    total_readable_count = len(readable_image_paths)\n",
    "    return total_readable_count, unreadable_skipped_count, len(train_image_paths), len(validation_image_paths)\n",
    "\n",
    "\n",
    "cats_total, cats_skipped, cats_train, cats_validation = split_class_directory_into_train_and_validation(\n",
    "    class_name=\"cats\",\n",
    "    combined_pool_class_directory=combined_pool_cats_directory,\n",
    "    train_split_class_directory=train_split_cats_directory,\n",
    "    validation_split_class_directory=validation_split_cats_directory,\n",
    ")\n",
    "\n",
    "dogs_total, dogs_skipped, dogs_train, dogs_validation = split_class_directory_into_train_and_validation(\n",
    "    class_name=\"dogs\",\n",
    "    combined_pool_class_directory=combined_pool_dogs_directory,\n",
    "    train_split_class_directory=train_split_dogs_directory,\n",
    "    validation_split_class_directory=validation_split_dogs_directory,\n",
    ")\n",
    "\n",
    "unknown_total, unknown_skipped, unknown_train, unknown_validation = split_class_directory_into_train_and_validation(\n",
    "    class_name=\"unknown\",\n",
    "    combined_pool_class_directory=combined_pool_unknown_directory,\n",
    "    train_split_class_directory=train_split_unknown_directory,\n",
    "    validation_split_class_directory=validation_split_unknown_directory,\n",
    ")\n",
    "\n",
    "print(\"Train and validation split results\")\n",
    "print(f\"  Training split ratio: {training_split_ratio}\")\n",
    "print(f\"  Cats, total readable: {cats_total}\")\n",
    "print(f\"  Skipped unreadable: {cats_skipped}\")\n",
    "print(f\"  Copied to train (cats): {cats_train}\")\n",
    "print(f\"  Copied to validation (cats): {cats_validation}\")\n",
    "print(f\"  Dogs, total readable: {dogs_total}\")\n",
    "print(f\"  Skipped unreadable: {dogs_skipped}\")\n",
    "print(f\"  Copied to train (dogs): {dogs_train}\")\n",
    "print(f\"  Copied to validation (dogs): {dogs_validation}\")\n",
    "print(f\"  Unknown, total readable: {unknown_total}\")\n",
    "print(f\"  Skipped unreadable: {unknown_skipped}\")\n",
    "print(f\"  Copied to train (unknown): {unknown_train}\")\n",
    "print(f\"  Copied to validation (unknown): {unknown_validation}\")\n",
    "print(\"\")\n",
    "print(f\"Train split folder: {train_split_directory}\")\n",
    "print(f\"Validation split folder: {validation_split_directory}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658f412d",
   "metadata": {},
   "source": [
    "## Create Training and Validation Data Generators\n",
    "\n",
    "This section sets up the image input pipeline for model training.\n",
    "\n",
    "It loads images from `Datasets/Splits/train_split` and `Datasets/Splits/validation_split`, applies data augmentation to the training set, rescales pixel values to the range 0–1, and ensures the class order is fixed as:\n",
    "\n",
    "`cats → dogs → unknown`\n",
    "\n",
    "It then calculates `steps_per_epoch` and `validation_steps`, and prints the class indices plus the number of samples per class for both training and validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9faa5f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47738 images belonging to 3 classes.\n",
      "Found 11936 images belonging to 3 classes.\n",
      "Class indices: {'cats': 0, 'dogs': 1, 'unknown': 2}\n",
      "Train samples: 47738\n",
      "Validation samples: 11936\n",
      "Train class counts: {'cats': 10741, 'dogs': 10717, 'unknown': 26280}\n",
      "Validation class counts: {'cats': 2686, 'dogs': 2680, 'unknown': 6570}\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 32\n",
    "image_height = 224\n",
    "image_width = 224\n",
    "epochs = 15\n",
    "\n",
    "training_image_generator = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    "    brightness_range=(0.9, 1.1),\n",
    ")\n",
    "\n",
    "validation_image_generator = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "class_names_in_order = [\"cats\", \"dogs\", \"unknown\"]\n",
    "\n",
    "train_data_gen = training_image_generator.flow_from_directory(\n",
    "    directory=str(train_split_directory),\n",
    "    target_size=(image_height, image_width),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    classes=class_names_in_order,\n",
    "    shuffle=True,\n",
    "    seed=random_seed,\n",
    ")\n",
    "\n",
    "val_data_gen = validation_image_generator.flow_from_directory(\n",
    "    directory=str(validation_split_directory),\n",
    "    target_size=(image_height, image_width),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    classes=class_names_in_order,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "steps_per_epoch = ceil(train_data_gen.n / batch_size)\n",
    "validation_steps = ceil(val_data_gen.n / batch_size)\n",
    "\n",
    "print(\"Class indices:\", train_data_gen.class_indices)\n",
    "print(\"Train samples:\", train_data_gen.n)\n",
    "print(\"Validation samples:\", val_data_gen.n)\n",
    "\n",
    "train_counts_by_class_index = np.bincount(train_data_gen.classes, minlength=len(class_names_in_order))\n",
    "validation_counts_by_class_index = np.bincount(val_data_gen.classes, minlength=len(class_names_in_order))\n",
    "\n",
    "print(\"Train class counts:\", dict(zip(class_names_in_order, train_counts_by_class_index.tolist())))\n",
    "print(\"Validation class counts:\", dict(zip(class_names_in_order, validation_counts_by_class_index.tolist())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276c3b87",
   "metadata": {},
   "source": [
    "## Train and Fine Tune the Model (Tuning Stage)\n",
    "\n",
    "This section trains the `cats`, `dogs`, `unknown` classifier using transfer learning with **MobileNetV2** and evaluates progress on the validation split.\n",
    "\n",
    "It runs in two phases:\n",
    "\n",
    "- **Phase 1 (feature extraction):** MobileNetV2 is fully frozen and only the custom classification head is trained.\n",
    "- **Phase 2 (fine tuning):** MobileNetV2 is partially unfrozen so only the last ~30 layers are trainable (earlier layers stay frozen), and training continues with a smaller learning rate to gently refine the pretrained features.\n",
    "\n",
    "Training uses early stopping and learning rate reduction based on validation loss, applies class weighting, saves the training history and class indices, and plots loss and accuracy curves.\n",
    "\n",
    "This is a tuning stage, the final model will be retrained later on `train_split + validation_split` and saved once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcdefb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 47738\n",
      "Training class counts: {'cats': 10741, 'dogs': 10717, 'unknown': 26280}\n",
      "Class weight: {0: 1.4814883778667411, 1: 1.4848060713508133, 2: 0.6055048198883816}\n",
      "Epoch 1/15\n",
      "\u001b[1m 456/1492\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:49\u001b[0m 395ms/step - accuracy: 0.7996 - loss: 0.6085"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\223023795\\AppData\\Local\\Python\\pythoncore-3.12-64\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:949: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m686s\u001b[0m 457ms/step - accuracy: 0.9451 - loss: 0.3262 - val_accuracy: 0.9815 - val_loss: 0.2446 - learning_rate: 1.0000e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1142s\u001b[0m 765ms/step - accuracy: 0.9740 - loss: 0.2631 - val_accuracy: 0.9817 - val_loss: 0.2454 - learning_rate: 1.0000e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2417s\u001b[0m 2s/step - accuracy: 0.9768 - loss: 0.2522 - val_accuracy: 0.9827 - val_loss: 0.2399 - learning_rate: 1.0000e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1758s\u001b[0m 1s/step - accuracy: 0.9796 - loss: 0.2436 - val_accuracy: 0.9834 - val_loss: 0.2331 - learning_rate: 1.0000e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m564s\u001b[0m 378ms/step - accuracy: 0.9802 - loss: 0.2421 - val_accuracy: 0.9832 - val_loss: 0.2311 - learning_rate: 1.0000e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m549s\u001b[0m 368ms/step - accuracy: 0.9806 - loss: 0.2397 - val_accuracy: 0.9846 - val_loss: 0.2284 - learning_rate: 1.0000e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m580s\u001b[0m 389ms/step - accuracy: 0.9817 - loss: 0.2376 - val_accuracy: 0.9856 - val_loss: 0.2225 - learning_rate: 1.0000e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1044s\u001b[0m 700ms/step - accuracy: 0.9825 - loss: 0.2344 - val_accuracy: 0.9853 - val_loss: 0.2240 - learning_rate: 1.0000e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1283s\u001b[0m 860ms/step - accuracy: 0.9831 - loss: 0.2312 - val_accuracy: 0.9864 - val_loss: 0.2185 - learning_rate: 1.0000e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m571s\u001b[0m 382ms/step - accuracy: 0.9838 - loss: 0.2316 - val_accuracy: 0.9859 - val_loss: 0.2191 - learning_rate: 1.0000e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step - accuracy: 0.9835 - loss: 0.2315\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m558s\u001b[0m 374ms/step - accuracy: 0.9834 - loss: 0.2302 - val_accuracy: 0.9854 - val_loss: 0.2235 - learning_rate: 1.0000e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m538s\u001b[0m 360ms/step - accuracy: 0.9830 - loss: 0.2284 - val_accuracy: 0.9858 - val_loss: 0.2210 - learning_rate: 5.0000e-05\n",
      "Epoch 1/8\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m672s\u001b[0m 447ms/step - accuracy: 0.9732 - loss: 0.2577 - val_accuracy: 0.9855 - val_loss: 0.2201 - learning_rate: 1.0000e-05\n",
      "Epoch 2/8\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2283s\u001b[0m 2s/step - accuracy: 0.9801 - loss: 0.2404 - val_accuracy: 0.9869 - val_loss: 0.2160 - learning_rate: 1.0000e-05\n",
      "Epoch 3/8\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m674s\u001b[0m 451ms/step - accuracy: 0.9820 - loss: 0.2322 - val_accuracy: 0.9878 - val_loss: 0.2123 - learning_rate: 1.0000e-05\n",
      "Epoch 4/8\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - accuracy: 0.9830 - loss: 0.2281\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m591s\u001b[0m 396ms/step - accuracy: 0.9839 - loss: 0.2257 - val_accuracy: 0.9873 - val_loss: 0.2131 - learning_rate: 1.0000e-05\n",
      "Epoch 5/8\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m644s\u001b[0m 432ms/step - accuracy: 0.9849 - loss: 0.2244 - val_accuracy: 0.9879 - val_loss: 0.2100 - learning_rate: 5.0000e-06\n",
      "Epoch 6/8\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m625s\u001b[0m 419ms/step - accuracy: 0.9855 - loss: 0.2215 - val_accuracy: 0.9883 - val_loss: 0.2096 - learning_rate: 5.0000e-06\n",
      "Epoch 7/8\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m512s\u001b[0m 343ms/step - accuracy: 0.9857 - loss: 0.2195 - val_accuracy: 0.9887 - val_loss: 0.2077 - learning_rate: 5.0000e-06\n",
      "Epoch 8/8\n",
      "\u001b[1m1492/1492\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 339ms/step - accuracy: 0.9854 - loss: 0.2191 - val_accuracy: 0.9884 - val_loss: 0.2070 - learning_rate: 5.0000e-06\n",
      "Saved training history to: C:\\Users\\223023795\\Desktop\\Cat and Dog Classifier\\AI Model\\outputs\\training_history_cell_a.json\n",
      "Saved class indices to: C:\\Users\\223023795\\Desktop\\Cat and Dog Classifier\\AI Model\\outputs\\class_indices.json\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "ai_model_directory = Path(base_project_directory) / \"AI Model\"\n",
    "saved_models_directory = ai_model_directory / \"models\"\n",
    "outputs_directory = ai_model_directory / \"outputs\"\n",
    "\n",
    "saved_models_directory.mkdir(parents=True, exist_ok=True)\n",
    "outputs_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "class_names_in_order = [\"cats\", \"dogs\", \"unknown\"]\n",
    "number_of_classes = len(class_names_in_order)\n",
    "\n",
    "expected_class_indices = {\"cats\": 0, \"dogs\": 1, \"unknown\": 2}\n",
    "if train_data_gen.class_indices != expected_class_indices:\n",
    "    raise RuntimeError(\n",
    "        f\"Unexpected class indices: {train_data_gen.class_indices}. \"\n",
    "        f\"Expected: {expected_class_indices}\"\n",
    "    )\n",
    "\n",
    "tf.keras.utils.set_random_seed(random_seed)\n",
    "\n",
    "# Compute class weights from the training generator distribution.\n",
    "train_class_counts = np.bincount(train_data_gen.classes, minlength=number_of_classes)\n",
    "if np.any(train_class_counts == 0):\n",
    "    raise RuntimeError(f\"At least one class has 0 samples in training: {train_class_counts.tolist()}\")\n",
    "\n",
    "total_train_samples = int(train_class_counts.sum())\n",
    "class_weight = {\n",
    "    class_index: total_train_samples / (number_of_classes * int(class_count))\n",
    "    for class_index, class_count in enumerate(train_class_counts)\n",
    "}\n",
    "\n",
    "print(\"Training samples:\", total_train_samples)\n",
    "print(\"Training class counts:\", dict(zip(class_names_in_order, train_class_counts.tolist())))\n",
    "print(\"Class weight:\", class_weight)\n",
    "\n",
    "# Build the model.\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(image_height, image_width, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "model_inputs = tf.keras.Input(shape=(image_height, image_width, 3))\n",
    "preprocessed_inputs = tf.keras.applications.mobilenet_v2.preprocess_input(model_inputs * 255.0)\n",
    "feature_maps = base_model(preprocessed_inputs, training=False)\n",
    "pooled_features = tf.keras.layers.GlobalAveragePooling2D()(feature_maps)\n",
    "pooled_features = tf.keras.layers.Dropout(0.3)(pooled_features)\n",
    "hidden_features = tf.keras.layers.Dense(256, activation=\"relu\")(pooled_features)\n",
    "hidden_features = tf.keras.layers.Dropout(0.3)(hidden_features)\n",
    "model_outputs = tf.keras.layers.Dense(number_of_classes, activation=\"softmax\")(hidden_features)\n",
    "\n",
    "model = tf.keras.Model(inputs=model_inputs, outputs=model_outputs)\n",
    "\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.05)\n",
    "\n",
    "# Phase 1: feature extraction.\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=loss_function,\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "early_stopping_callback = callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "learning_rate_scheduler = callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "history_phase_1 = model.fit(\n",
    "    train_data_gen,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stopping_callback, learning_rate_scheduler],\n",
    "    class_weight=class_weight,\n",
    ")\n",
    "\n",
    "# Phase 2: fine tuning (unfreeze last N layers).\n",
    "fine_tune_layers_to_unfreeze = 30\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-fine_tune_layers_to_unfreeze]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=loss_function,\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "early_stopping_callback_phase_2 = callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    patience=2,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "learning_rate_scheduler_phase_2 = callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=1,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "history_phase_2 = model.fit(\n",
    "    train_data_gen,\n",
    "    epochs=8,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stopping_callback_phase_2, learning_rate_scheduler_phase_2],\n",
    "    class_weight=class_weight,\n",
    ")\n",
    "\n",
    "# Combine history (Phase 1 + Phase 2) so plots and exports are continuous.\n",
    "combined_history = {}\n",
    "for key in set(history_phase_1.history.keys()).union(set(history_phase_2.history.keys())):\n",
    "    combined_history[key] = history_phase_1.history.get(key, []) + history_phase_2.history.get(key, [])\n",
    "\n",
    "training_history_file_path = outputs_directory / \"training_history_cell_a.json\"\n",
    "with open(training_history_file_path, \"w\", encoding=\"utf-8\") as history_file:\n",
    "    json.dump(combined_history, history_file, indent=2)\n",
    "print(\"Saved training history to:\", training_history_file_path)\n",
    "\n",
    "class_indices_file_path = outputs_directory / \"class_indices.json\"\n",
    "with open(class_indices_file_path, \"w\", encoding=\"utf-8\") as class_file:\n",
    "    json.dump(train_data_gen.class_indices, class_file, indent=2)\n",
    "print(\"Saved class indices to:\", class_indices_file_path)\n",
    "\n",
    "training_loss_values = combined_history.get(\"loss\", [])\n",
    "validation_loss_values = combined_history.get(\"val_loss\", [])\n",
    "training_accuracy_values = combined_history.get(\"accuracy\", [])\n",
    "validation_accuracy_values = combined_history.get(\"val_accuracy\", [])\n",
    "\n",
    "epochs_ran = range(1, len(training_loss_values) + 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs_ran, training_loss_values, label=\"Training loss\")\n",
    "plt.plot(epochs_ran, validation_loss_values, label=\"Validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss over epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs_ran, training_accuracy_values, label=\"Training accuracy\")\n",
    "plt.plot(epochs_ran, validation_accuracy_values, label=\"Validation accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy over epochs\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c310b4",
   "metadata": {},
   "source": [
    "## Tune the Unknown Confidence Threshold (Validation Only)\n",
    "\n",
    "This section finds the best confidence threshold for forcing a prediction to `unknown` when the model is not confident enough.\n",
    "\n",
    "It runs the trained model on the **validation split** to get softmax probabilities, then tests a range of thresholds (default `0.40` to `0.70` in steps of `0.01`). For each threshold it reports:\n",
    "\n",
    "- How often real cats and dogs are rejected into `unknown`\n",
    "- How often real `unknown` images are incorrectly accepted as cat or dog\n",
    "- Accuracy on known classes (`cats + dogs`) and overall accuracy\n",
    "\n",
    "The chosen threshold is the one that first satisfies all guardrails (`cat_reject <= 1%`, `dog_reject <= 1%`, `unknown_false_accept <= 10%`) and, among those, maximizes known-class accuracy (`cats + dogs`) with tie-breakers favoring lower unknown false accepts, then lower cat/dog rejects.\n",
    "\n",
    "All threshold results are stored, then the script prints the **top 10 thresholds** and returns the chosen threshold to be reused unchanged for the final test evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "700b7a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11936 images belonging to 3 classes.\n",
      "\n",
      "Predicting probabilities on validation set...\n",
      "Total validation images: 11936\n",
      "Batch size: 32\n",
      "Steps: 373\n",
      "Class indices: {'cats': 0, 'dogs': 1, 'unknown': 2}\n",
      "\n",
      "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 151ms/step\n",
      "\n",
      "threshold | cat_reject% | dog_reject% | unk_false_accept% | unk_recall% | known_acc% | overall_acc%\n",
      "--------- | ---------- | ---------- | ---------------- | ---------- | --------- | -----------\n",
      "    0.40 |      0.26 |      0.56 |            1.05 |     98.95 |    98.71 |      98.84\n",
      "    0.41 |      0.26 |      0.56 |            1.05 |     98.95 |    98.71 |      98.84\n",
      "    0.42 |      0.26 |      0.56 |            1.05 |     98.95 |    98.71 |      98.84\n",
      "    0.43 |      0.26 |      0.56 |            1.05 |     98.95 |    98.71 |      98.84\n",
      "    0.44 |      0.26 |      0.56 |            1.04 |     98.96 |    98.71 |      98.85\n",
      "    0.45 |      0.26 |      0.56 |            1.04 |     98.96 |    98.71 |      98.85\n",
      "    0.46 |      0.26 |      0.56 |            1.02 |     98.98 |    98.71 |      98.86\n",
      "    0.47 |      0.34 |      0.56 |            1.02 |     98.98 |    98.70 |      98.85\n",
      "    0.48 |      0.34 |      0.56 |            1.02 |     98.98 |    98.70 |      98.85\n",
      "    0.49 |      0.34 |      0.60 |            0.99 |     99.01 |    98.70 |      98.87\n",
      "    0.50 |      0.37 |      0.63 |            0.97 |     99.03 |    98.68 |      98.87\n",
      "    0.51 |      0.37 |      0.67 |            0.94 |     99.06 |    98.66 |      98.88\n",
      "    0.52 |      0.41 |      0.71 |            0.91 |     99.09 |    98.62 |      98.88\n",
      "    0.53 |      0.41 |      0.71 |            0.90 |     99.10 |    98.62 |      98.89\n",
      "    0.54 |      0.48 |      0.78 |            0.90 |     99.10 |    98.57 |      98.86\n",
      "    0.55 |      0.52 |      0.78 |            0.90 |     99.10 |    98.55 |      98.85\n",
      "    0.56 |      0.67 |      0.78 |            0.90 |     99.10 |    98.51 |      98.84\n",
      "    0.57 |      0.71 |      0.86 |            0.88 |     99.12 |    98.45 |      98.82\n",
      "    0.58 |      0.82 |      0.90 |            0.85 |     99.15 |    98.43 |      98.83\n",
      "    0.59 |      0.89 |      0.97 |            0.85 |     99.15 |    98.40 |      98.81\n",
      "    0.60 |      0.89 |      1.08 |            0.84 |     99.16 |    98.34 |      98.79\n",
      "    0.61 |      0.93 |      1.16 |            0.81 |     99.19 |    98.34 |      98.81\n",
      "    0.62 |      1.04 |      1.23 |            0.79 |     99.21 |    98.27 |      98.79\n",
      "    0.63 |      1.15 |      1.23 |            0.75 |     99.25 |    98.21 |      98.79\n",
      "    0.64 |      1.19 |      1.27 |            0.75 |     99.25 |    98.19 |      98.78\n",
      "    0.65 |      1.19 |      1.34 |            0.73 |     99.27 |    98.16 |      98.77\n",
      "    0.66 |      1.27 |      1.42 |            0.68 |     99.32 |    98.12 |      98.78\n",
      "    0.67 |      1.38 |      1.46 |            0.68 |     99.32 |    98.10 |      98.77\n",
      "    0.68 |      1.45 |      1.49 |            0.67 |     99.33 |    98.04 |      98.75\n",
      "    0.69 |      1.49 |      1.60 |            0.65 |     99.35 |    97.99 |      98.73\n",
      "    0.70 |      1.56 |      1.64 |            0.62 |     99.38 |    97.95 |      98.73\n",
      "\n",
      "Top 10 thresholds that meet constraints\n",
      " 1. threshold=0.46 | known_acc=98.71% | unk_false_accept=1.02% | cat_reject=0.26% | dog_reject=0.56% | overall_acc=98.86%\n",
      " 2. threshold=0.44 | known_acc=98.71% | unk_false_accept=1.04% | cat_reject=0.26% | dog_reject=0.56% | overall_acc=98.85%\n",
      " 3. threshold=0.45 | known_acc=98.71% | unk_false_accept=1.04% | cat_reject=0.26% | dog_reject=0.56% | overall_acc=98.85%\n",
      " 4. threshold=0.40 | known_acc=98.71% | unk_false_accept=1.05% | cat_reject=0.26% | dog_reject=0.56% | overall_acc=98.84%\n",
      " 5. threshold=0.41 | known_acc=98.71% | unk_false_accept=1.05% | cat_reject=0.26% | dog_reject=0.56% | overall_acc=98.84%\n",
      " 6. threshold=0.42 | known_acc=98.71% | unk_false_accept=1.05% | cat_reject=0.26% | dog_reject=0.56% | overall_acc=98.84%\n",
      " 7. threshold=0.43 | known_acc=98.71% | unk_false_accept=1.05% | cat_reject=0.26% | dog_reject=0.56% | overall_acc=98.84%\n",
      " 8. threshold=0.49 | known_acc=98.70% | unk_false_accept=0.99% | cat_reject=0.34% | dog_reject=0.60% | overall_acc=98.87%\n",
      " 9. threshold=0.47 | known_acc=98.70% | unk_false_accept=1.02% | cat_reject=0.34% | dog_reject=0.56% | overall_acc=98.85%\n",
      "10. threshold=0.48 | known_acc=98.70% | unk_false_accept=1.02% | cat_reject=0.34% | dog_reject=0.56% | overall_acc=98.85%\n",
      "\n",
      "Chosen threshold (validation only): 0.46\n",
      "Known accuracy (cats+dogs only): 98.71%\n",
      "Unknown false accept rate: 1.02%\n",
      "\n",
      "Returned threshold: 0.46\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import ceil\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Force \"unknown\" if max probability is below the confidence threshold.\n",
    "def apply_unknown_threshold(\n",
    "    probabilities: np.ndarray,\n",
    "    confidence_threshold: float,\n",
    "    unknown_class_index: int,\n",
    ") -> np.ndarray:\n",
    "    probabilities = np.asarray(probabilities)\n",
    "\n",
    "    if probabilities.ndim != 2:\n",
    "        raise ValueError(f\"probabilities must be 2D (num_samples, num_classes). Got: {probabilities.shape}\")\n",
    "\n",
    "    maximum_probabilities = probabilities.max(axis=1)\n",
    "    predicted_indices = probabilities.argmax(axis=1).astype(int)\n",
    "\n",
    "    predicted_indices = np.where(\n",
    "        maximum_probabilities < confidence_threshold,\n",
    "        unknown_class_index,\n",
    "        predicted_indices,\n",
    "    )\n",
    "\n",
    "    return predicted_indices\n",
    "\n",
    "\n",
    "# Tune the confidence threshold using validation only, then freeze it for test.\n",
    "def tune_best_confidence_threshold_on_validation(\n",
    "    model,\n",
    "    validation_split_directory,\n",
    "    image_height: int,\n",
    "    image_width: int,\n",
    "    batch_size: int,\n",
    "    threshold_values: list[float] | None = None,\n",
    "    class_folder_names: list[str] | None = None,\n",
    "    unknown_folder_name: str = \"unknown\",\n",
    "    maximum_known_reject_rate: float = 0.01,\n",
    "    maximum_unknown_false_accept_rate: float = 0.10,\n",
    "    top_thresholds_to_show: int = 10,\n",
    ") -> float:\n",
    "    if threshold_values is None:\n",
    "        threshold_values = [value / 100 for value in range(40, 71)]\n",
    "\n",
    "    if class_folder_names is None:\n",
    "        class_folder_names = [\"cats\", \"dogs\", \"unknown\"]\n",
    "\n",
    "    validation_generator = ImageDataGenerator(rescale=1.0 / 255.0).flow_from_directory(\n",
    "        directory=str(validation_split_directory),\n",
    "        target_size=(image_height, image_width),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "        classes=class_folder_names,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    if validation_generator.n == 0:\n",
    "        raise ValueError(\"Validation directory contains 0 images, cannot tune threshold.\")\n",
    "\n",
    "    if unknown_folder_name not in validation_generator.class_indices:\n",
    "        raise ValueError(\n",
    "            f\"Unknown folder '{unknown_folder_name}' not found. class_indices: {validation_generator.class_indices}\"\n",
    "        )\n",
    "\n",
    "    if \"cats\" not in validation_generator.class_indices or \"dogs\" not in validation_generator.class_indices:\n",
    "        raise ValueError(f\"Expected 'cats' and 'dogs' folders. class_indices: {validation_generator.class_indices}\")\n",
    "\n",
    "    cat_class_index = int(validation_generator.class_indices[\"cats\"])\n",
    "    dog_class_index = int(validation_generator.class_indices[\"dogs\"])\n",
    "    unknown_class_index = int(validation_generator.class_indices[unknown_folder_name])\n",
    "\n",
    "    true_indices = validation_generator.classes.astype(int)\n",
    "\n",
    "    cat_mask = true_indices == cat_class_index\n",
    "    dog_mask = true_indices == dog_class_index\n",
    "    unknown_mask = true_indices == unknown_class_index\n",
    "    known_mask = cat_mask | dog_mask\n",
    "\n",
    "    total_steps = ceil(validation_generator.n / batch_size)\n",
    "\n",
    "    print(\"\\nPredicting probabilities on validation set...\")\n",
    "    print(f\"Total validation images: {validation_generator.n}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    print(f\"Steps: {total_steps}\")\n",
    "    print(f\"Class indices: {validation_generator.class_indices}\\n\")\n",
    "\n",
    "    validation_probabilities = model.predict(\n",
    "        validation_generator,\n",
    "        steps=total_steps,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    threshold_results: list[dict] = []\n",
    "\n",
    "    print(\"\\nthreshold | cat_reject% | dog_reject% | unk_false_accept% | unk_recall% | known_acc% | overall_acc%\")\n",
    "    print(\"--------- | ---------- | ---------- | ---------------- | ---------- | --------- | -----------\")\n",
    "\n",
    "    for confidence_threshold in threshold_values:\n",
    "        predicted_indices = apply_unknown_threshold(\n",
    "            probabilities=validation_probabilities,\n",
    "            confidence_threshold=confidence_threshold,\n",
    "            unknown_class_index=unknown_class_index,\n",
    "        )\n",
    "\n",
    "        cat_reject_rate = float(np.mean(predicted_indices[cat_mask] == unknown_class_index)) if np.any(cat_mask) else 0.0\n",
    "        dog_reject_rate = float(np.mean(predicted_indices[dog_mask] == unknown_class_index)) if np.any(dog_mask) else 0.0\n",
    "        known_reject_sum = cat_reject_rate + dog_reject_rate\n",
    "\n",
    "        unknown_false_accept_rate = float(\n",
    "            np.mean(predicted_indices[unknown_mask] != unknown_class_index)\n",
    "        ) if np.any(unknown_mask) else 0.0\n",
    "        unknown_recall = 1.0 - unknown_false_accept_rate if np.any(unknown_mask) else 0.0\n",
    "\n",
    "        known_accuracy = float(\n",
    "            np.mean(predicted_indices[known_mask] == true_indices[known_mask])\n",
    "        ) if np.any(known_mask) else 0.0\n",
    "        overall_accuracy = float(np.mean(predicted_indices == true_indices))\n",
    "\n",
    "        meets_known_reject_constraint = (cat_reject_rate <= maximum_known_reject_rate) and (\n",
    "            dog_reject_rate <= maximum_known_reject_rate\n",
    "        )\n",
    "        meets_unknown_accept_constraint = unknown_false_accept_rate <= maximum_unknown_false_accept_rate\n",
    "        meets_constraints = bool(meets_known_reject_constraint and meets_unknown_accept_constraint)\n",
    "\n",
    "        threshold_results.append(\n",
    "            {\n",
    "                \"threshold\": float(confidence_threshold),\n",
    "                \"cat_reject_rate\": float(cat_reject_rate),\n",
    "                \"dog_reject_rate\": float(dog_reject_rate),\n",
    "                \"known_reject_sum\": float(known_reject_sum),\n",
    "                \"unknown_false_accept_rate\": float(unknown_false_accept_rate),\n",
    "                \"unknown_recall\": float(unknown_recall),\n",
    "                \"known_accuracy\": float(known_accuracy),\n",
    "                \"overall_accuracy\": float(overall_accuracy),\n",
    "                \"meets_constraints\": meets_constraints,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"{confidence_threshold:8.2f} |\"\n",
    "            f\"{cat_reject_rate*100:10.2f} |\"\n",
    "            f\"{dog_reject_rate*100:10.2f} |\"\n",
    "            f\"{unknown_false_accept_rate*100:16.2f} |\"\n",
    "            f\"{unknown_recall*100:10.2f} |\"\n",
    "            f\"{known_accuracy*100:9.2f} |\"\n",
    "            f\"{overall_accuracy*100:11.2f}\"\n",
    "        )\n",
    "\n",
    "    eligible_results = [row for row in threshold_results if row[\"meets_constraints\"]]\n",
    "\n",
    "    def sort_key_for_constraints(row: dict) -> tuple:\n",
    "        return (\n",
    "            -row[\"known_accuracy\"],\n",
    "            row[\"unknown_false_accept_rate\"],\n",
    "            row[\"known_reject_sum\"],\n",
    "            -row[\"overall_accuracy\"],\n",
    "        )\n",
    "\n",
    "    if eligible_results:\n",
    "        eligible_results_sorted = sorted(eligible_results, key=sort_key_for_constraints)\n",
    "        best_row = eligible_results_sorted[0]\n",
    "\n",
    "        print(f\"\\nTop {min(top_thresholds_to_show, len(eligible_results_sorted))} thresholds that meet constraints\")\n",
    "        for index, row in enumerate(eligible_results_sorted[:top_thresholds_to_show], start=1):\n",
    "            print(\n",
    "                f\"{index:2d}. threshold={row['threshold']:.2f} | \"\n",
    "                f\"known_acc={row['known_accuracy']*100:.2f}% | \"\n",
    "                f\"unk_false_accept={row['unknown_false_accept_rate']*100:.2f}% | \"\n",
    "                f\"cat_reject={row['cat_reject_rate']*100:.2f}% | \"\n",
    "                f\"dog_reject={row['dog_reject_rate']*100:.2f}% | \"\n",
    "                f\"overall_acc={row['overall_accuracy']*100:.2f}%\"\n",
    "            )\n",
    "\n",
    "        print(\"\\nChosen threshold (validation only):\", f\"{best_row['threshold']:.2f}\")\n",
    "        print(\"Known accuracy (cats+dogs only):\", f\"{best_row['known_accuracy']*100:.2f}%\")\n",
    "        print(\"Unknown false accept rate:\", f\"{best_row['unknown_false_accept_rate']*100:.2f}%\")\n",
    "        return float(best_row[\"threshold\"])\n",
    "\n",
    "    known_reject_weight = 2.0\n",
    "    unknown_false_accept_weight = 3.0\n",
    "\n",
    "    for row in threshold_results:\n",
    "        average_known_reject_rate = (row[\"cat_reject_rate\"] + row[\"dog_reject_rate\"]) / 2.0\n",
    "        row[\"fallback_score\"] = (\n",
    "            row[\"known_accuracy\"]\n",
    "            - unknown_false_accept_weight * row[\"unknown_false_accept_rate\"]\n",
    "            - known_reject_weight * average_known_reject_rate\n",
    "        )\n",
    "\n",
    "    threshold_results_sorted = sorted(threshold_results, key=lambda row: row[\"fallback_score\"], reverse=True)\n",
    "    best_row = threshold_results_sorted[0]\n",
    "\n",
    "    print(\"\\nNo threshold met both constraints.\")\n",
    "    print(f\"\\nTop {min(top_thresholds_to_show, len(threshold_results_sorted))} thresholds by fallback score\")\n",
    "    for index, row in enumerate(threshold_results_sorted[:top_thresholds_to_show], start=1):\n",
    "        print(\n",
    "            f\"{index:2d}. threshold={row['threshold']:.2f} | \"\n",
    "            f\"score={row['fallback_score']:.6f} | \"\n",
    "            f\"known_acc={row['known_accuracy']*100:.2f}% | \"\n",
    "            f\"unk_false_accept={row['unknown_false_accept_rate']*100:.2f}% | \"\n",
    "            f\"cat_reject={row['cat_reject_rate']*100:.2f}% | \"\n",
    "            f\"dog_reject={row['dog_reject_rate']*100:.2f}% | \"\n",
    "            f\"overall_acc={row['overall_accuracy']*100:.2f}%\"\n",
    "        )\n",
    "\n",
    "    print(\"\\nFallback chosen threshold (validation only):\", f\"{best_row['threshold']:.2f}\")\n",
    "    print(\"Tip: loosen maximum_known_reject_rate or maximum_unknown_false_accept_rate slightly if you want a constrained solution.\")\n",
    "    return float(best_row[\"threshold\"])\n",
    "\n",
    "\n",
    "chosen_threshold = tune_best_confidence_threshold_on_validation(\n",
    "    model=model,\n",
    "    validation_split_directory=validation_split_directory,\n",
    "    image_height=image_height,\n",
    "    image_width=image_width,\n",
    "    batch_size=batch_size,\n",
    "    maximum_known_reject_rate=0.01,\n",
    "    maximum_unknown_false_accept_rate=0.10,\n",
    "    top_thresholds_to_show=10,\n",
    ")\n",
    "\n",
    "print(\"\\nReturned threshold:\", chosen_threshold)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dc4a24",
   "metadata": {},
   "source": [
    "## Final Training Run (Train + Validation Combined)\n",
    "\n",
    "This section produces the single final model for the project.\n",
    "\n",
    "It uses the best epoch counts found during training in the first training step and the frozen confidence threshold tuned on validation only from the previous cell. Then it combines the train split and validation split into one larger training set and retrains the model in two phases:\n",
    "\n",
    "- **Phase 1 (feature extraction):** MobileNetV2 stays frozen and only the new classification head is trained.\n",
    "- **Phase 2 (fine-tuning):** the last **about 30 layers** of MobileNetV2 are unfrozen and trained with a lower learning rate.\n",
    "\n",
    "The number of epochs for each final-training phase is chosen from the first training run by taking the epoch where validation loss is lowest in that same phase.\n",
    "\n",
    "At the end, it saves the final `.keras` model plus the frozen threshold so the same decision rule is used for testing and in the web app.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e90771f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training plan (train + validation combined)\n",
      "  Phase 1 epochs (best val_loss epoch from first training cell): 9\n",
      "  Phase 2 epochs (best val_loss epoch from first training cell): 8\n",
      "  Frozen threshold (from threshold tuning cell, validation only): 0.46\n",
      "Found 47738 files belonging to 3 classes.\n",
      "Found 11936 files belonging to 3 classes.\n",
      "\n",
      "Combined training data ready\n",
      "  Train folder:      C:\\Users\\223023795\\Desktop\\Cat and Dog Classifier\\Datasets\\Splits\\train_split\n",
      "  Validation folder: C:\\Users\\223023795\\Desktop\\Cat and Dog Classifier\\Datasets\\Splits\\validation_split\n",
      "  Class order: ['cats', 'dogs', 'unknown']\n",
      "Epoch 1/9\n",
      "\u001b[1m1865/1865\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 153ms/step - accuracy: 0.9515 - loss: 0.3083 - learning_rate: 1.0000e-04\n",
      "Epoch 2/9\n",
      "\u001b[1m1865/1865\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 158ms/step - accuracy: 0.9742 - loss: 0.2532 - learning_rate: 1.0000e-04\n",
      "Epoch 3/9\n",
      "\u001b[1m1865/1865\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 159ms/step - accuracy: 0.9761 - loss: 0.2458 - learning_rate: 1.0000e-04\n",
      "Epoch 4/9\n",
      "\u001b[1m1865/1865\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 171ms/step - accuracy: 0.9771 - loss: 0.2420 - learning_rate: 1.0000e-04\n",
      "Epoch 5/9\n",
      "\u001b[1m1865/1865\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 177ms/step - accuracy: 0.9778 - loss: 0.2376 - learning_rate: 1.0000e-04\n",
      "Epoch 6/9\n",
      "\u001b[1m1865/1865\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 172ms/step - accuracy: 0.9791 - loss: 0.2353 - learning_rate: 1.0000e-04\n",
      "Epoch 7/9\n",
      "\u001b[1m1865/1865\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 169ms/step - accuracy: 0.9792 - loss: 0.2330 - learning_rate: 1.0000e-04\n",
      "Epoch 8/9\n",
      "\u001b[1m1865/1865\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 157ms/step - accuracy: 0.9798 - loss: 0.2320 - learning_rate: 1.0000e-04\n",
      "Epoch 9/9\n",
      "\u001b[1m1865/1865\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 154ms/step - accuracy: 0.9800 - loss: 0.2305 - learning_rate: 1.0000e-04\n",
      "Epoch 1/8\n",
      "\u001b[1m1865/1865\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 196ms/step - accuracy: 0.9734 - loss: 0.2490 - learning_rate: 1.0000e-05\n",
      "Epoch 2/8\n",
      "\u001b[1m1865/1865\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 195ms/step - accuracy: 0.9786 - loss: 0.2347 - learning_rate: 1.0000e-05\n",
      "Epoch 3/8\n",
      "\u001b[1m1865/1865\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 195ms/step - accuracy: 0.9807 - loss: 0.2283 - learning_rate: 1.0000e-05\n",
      "Epoch 4/8\n",
      "\u001b[1m1865/1865\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 194ms/step - accuracy: 0.9821 - loss: 0.2231 - learning_rate: 1.0000e-05\n",
      "Epoch 5/8\n",
      "\u001b[1m1865/1865\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 194ms/step - accuracy: 0.9833 - loss: 0.2197 - learning_rate: 1.0000e-05\n",
      "Epoch 6/8\n",
      "\u001b[1m1865/1865\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 194ms/step - accuracy: 0.9847 - loss: 0.2164 - learning_rate: 1.0000e-05\n",
      "Epoch 7/8\n",
      "\u001b[1m1865/1865\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 198ms/step - accuracy: 0.9856 - loss: 0.2139 - learning_rate: 1.0000e-05\n",
      "Epoch 8/8\n",
      "\u001b[1m1865/1865\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 195ms/step - accuracy: 0.9859 - loss: 0.2123 - learning_rate: 1.0000e-05\n",
      "\n",
      "Saved final model to: C:\\Users\\223023795\\Desktop\\Cat and Dog Classifier\\AI Model\\models\\cat_dog_unknown_classifier.keras\n",
      "Saved frozen threshold to: C:\\Users\\223023795\\Desktop\\Cat and Dog Classifier\\AI Model\\outputs\\frozen_threshold.json\n",
      "Saved final training history to: C:\\Users\\223023795\\Desktop\\Cat and Dog Classifier\\AI Model\\outputs\\final_training_history.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "\n",
    "# This cell assumes these already exist from earlier cells:\n",
    "# - train_split_directory, validation_split_directory\n",
    "# - image_height, image_width, batch_size, random_seed\n",
    "# - history_phase_1, history_phase_2 (from training cell)\n",
    "# - chosen_threshold (from threshold tuning cell)\n",
    "\n",
    "required_variable_names = [\n",
    "    \"train_split_directory\",\n",
    "    \"validation_split_directory\",\n",
    "    \"image_height\",\n",
    "    \"image_width\",\n",
    "    \"batch_size\",\n",
    "    \"random_seed\",\n",
    "    \"history_phase_1\",\n",
    "    \"history_phase_2\",\n",
    "    \"chosen_threshold\",\n",
    "    \"base_project_directory\",\n",
    "]\n",
    "missing_variable_names = [name for name in required_variable_names if name not in globals()]\n",
    "if missing_variable_names:\n",
    "    raise RuntimeError(\"Missing required variables: \" + \", \".join(missing_variable_names))\n",
    "\n",
    "\n",
    "class_names_in_order = [\"cats\", \"dogs\", \"unknown\"]\n",
    "number_of_classes = len(class_names_in_order)\n",
    "\n",
    "phase_1_validation_losses = history_phase_1.history.get(\"val_loss\", [])\n",
    "phase_2_validation_losses = history_phase_2.history.get(\"val_loss\", [])\n",
    "if not phase_1_validation_losses or not phase_2_validation_losses:\n",
    "    raise RuntimeError(\"First training cells histories must contain 'val_loss' so epochs can be selected reproducibly.\")\n",
    "\n",
    "phase_1_epochs_to_train = int(np.argmin(phase_1_validation_losses)) + 1\n",
    "phase_2_epochs_to_train = int(np.argmin(phase_2_validation_losses)) + 1\n",
    "\n",
    "print(\"Final training plan (train + validation combined)\")\n",
    "print(f\"  Phase 1 epochs (best val_loss epoch from first training cell): {phase_1_epochs_to_train}\")\n",
    "print(f\"  Phase 2 epochs (best val_loss epoch from first training cell): {phase_2_epochs_to_train}\")\n",
    "print(f\"  Frozen threshold (from threshold tuning cell, validation only): {float(chosen_threshold):.2f}\")\n",
    "\n",
    "\n",
    "# Create output folders for the final artifacts.\n",
    "ai_model_directory = Path(base_project_directory) / \"AI Model\"\n",
    "models_directory = ai_model_directory / \"models\"\n",
    "outputs_directory = ai_model_directory / \"outputs\"\n",
    "models_directory.mkdir(parents=True, exist_ok=True)\n",
    "outputs_directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "final_model_file_path = models_directory / \"cat_dog_unknown_classifier.keras\"\n",
    "frozen_threshold_file_path = outputs_directory / \"frozen_threshold.json\"\n",
    "final_training_history_file_path = outputs_directory / \"final_training_history.json\"\n",
    "\n",
    "\n",
    "# Build one combined dataset from the existing train and validation folders.\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=str(train_split_directory),\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=class_names_in_order,\n",
    "    image_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=random_seed,\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=str(validation_split_directory),\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=class_names_in_order,\n",
    "    image_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=random_seed,\n",
    ")\n",
    "\n",
    "combined_training_dataset = train_dataset.concatenate(validation_dataset)\n",
    "combined_training_dataset = combined_training_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"\\nCombined training data ready\")\n",
    "print(f\"  Train folder:      {train_split_directory}\")\n",
    "print(f\"  Validation folder: {validation_split_directory}\")\n",
    "print(\"  Class order:\", class_names_in_order)\n",
    "\n",
    "\n",
    "# Keep final training reproducible.\n",
    "tf.keras.utils.set_random_seed(random_seed)\n",
    "\n",
    "\n",
    "# Data augmentation for the final training run.\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(30 / 360),\n",
    "        tf.keras.layers.RandomTranslation(height_factor=0.15, width_factor=0.15),\n",
    "        tf.keras.layers.RandomZoom(0.15),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def preprocess_for_training(images, labels):\n",
    "    # Scale to [0, 1], then apply augmentation similar to your generator setup.\n",
    "    images = tf.cast(images, tf.float32) / 255.0\n",
    "    images = data_augmentation(images, training=True)\n",
    "    images = tf.image.random_brightness(images, max_delta=0.1)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "combined_training_dataset = (\n",
    "    combined_training_dataset\n",
    "    .map(preprocess_for_training, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "\n",
    "# Rebuild the same model recipe, then train once on the combined dataset.\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(image_height, image_width, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "model_inputs = tf.keras.Input(shape=(image_height, image_width, 3))\n",
    "preprocessed_inputs = tf.keras.applications.mobilenet_v2.preprocess_input(model_inputs * 255.0)\n",
    "feature_maps = base_model(preprocessed_inputs, training=False)\n",
    "pooled_features = tf.keras.layers.GlobalAveragePooling2D()(feature_maps)\n",
    "dropped_features = tf.keras.layers.Dropout(0.3)(pooled_features)\n",
    "hidden_features = tf.keras.layers.Dense(256, activation=\"relu\")(dropped_features)\n",
    "hidden_features = tf.keras.layers.Dropout(0.3)(hidden_features)\n",
    "model_outputs = tf.keras.layers.Dense(number_of_classes, activation=\"softmax\")(hidden_features)\n",
    "\n",
    "model = tf.keras.Model(inputs=model_inputs, outputs=model_outputs)\n",
    "\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.05)\n",
    "\n",
    "\n",
    "# Phase 1, feature extraction only.\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=loss_function,\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "learning_rate_scheduler_phase_1 = callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"loss\",\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "history_final_phase_1 = model.fit(\n",
    "    combined_training_dataset,\n",
    "    epochs=phase_1_epochs_to_train,\n",
    "    callbacks=[learning_rate_scheduler_phase_1],\n",
    ")\n",
    "\n",
    "\n",
    "# Phase 2, fine tuning by unfreezing the last part of MobileNetV2.\n",
    "fine_tune_layers_to_unfreeze = 30\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-fine_tune_layers_to_unfreeze]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=loss_function,\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "learning_rate_scheduler_phase_2 = callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"loss\",\n",
    "    factor=0.5,\n",
    "    patience=1,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "history_final_phase_2 = model.fit(\n",
    "    combined_training_dataset,\n",
    "    epochs=phase_2_epochs_to_train,\n",
    "    callbacks=[learning_rate_scheduler_phase_2],\n",
    ")\n",
    "\n",
    "\n",
    "# Save the final model and the frozen threshold for test evaluation and the web app.\n",
    "model.save(final_model_file_path)\n",
    "print(\"\\nSaved final model to:\", final_model_file_path)\n",
    "\n",
    "with open(frozen_threshold_file_path, \"w\", encoding=\"utf-8\") as threshold_file:\n",
    "    json.dump({\"chosen_threshold\": float(chosen_threshold)}, threshold_file, indent=2)\n",
    "print(\"Saved frozen threshold to:\", frozen_threshold_file_path)\n",
    "\n",
    "final_training_history = {\n",
    "    \"phase_1\": history_final_phase_1.history,\n",
    "    \"phase_2\": history_final_phase_2.history,\n",
    "    \"phase_1_epochs_trained\": phase_1_epochs_to_train,\n",
    "    \"phase_2_epochs_trained\": phase_2_epochs_to_train,\n",
    "    \"fine_tune_layers_to_unfreeze\": fine_tune_layers_to_unfreeze,\n",
    "    \"class_names_in_order\": class_names_in_order,\n",
    "}\n",
    "\n",
    "with open(final_training_history_file_path, \"w\", encoding=\"utf-8\") as history_file:\n",
    "    json.dump(final_training_history, history_file, indent=2)\n",
    "print(\"Saved final training history to:\", final_training_history_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee14936",
   "metadata": {},
   "source": [
    "## Final Test Evaluation on Holdout Datasets\n",
    "\n",
    "This section evaluates the **final trained model** using your **held-out test folders**.\n",
    "\n",
    "It loads the saved model and the frozen confidence threshold (chosen using validation only), then:\n",
    "\n",
    "- Runs **Oxford cats and dogs test** (`Datasets/Test/oxford_test`) to measure cats vs dogs performance, including how often real cats or dogs get rejected as **unknown** after applying the threshold.\n",
    "- Runs **unknown test sets** (`Datasets/Test/unknown_test/unknown_places` and `unknown_coco`) to measure how well the model routes non-cat/dog images to the **unknown** class after applying the same frozen threshold.\n",
    "- Prints an official **confusion matrix** at the end for the Oxford test (true cats and dogs vs predicted cats, dogs, unknown).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f3ccc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using frozen threshold from validation: 0.46\n",
      "Found 7390 files belonging to 2 classes.\n",
      "\u001b[1m231/231\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 264ms/step\n",
      "\n",
      "Oxford holdout results (cats/dogs only):\n",
      "Threshold: 0.46\n",
      "Total images: 7390\n",
      "Accuracy (unknown counted as wrong): 98.23 %\n",
      "Rejected as unknown rate: 0.49 %\n",
      "Cat recall: 96.08 %\n",
      "Dog recall: 99.26 %\n",
      "Cats rejected as unknown: 0.92 %\n",
      "Dogs rejected as unknown: 0.28 %\n",
      "\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      "                cats      dogs   unknown\n",
      "true cats         2306        72        22\n",
      "true dogs           23      4953        14\n",
      "\n",
      "Breakdown by true class:\n",
      "True cats: 2400 | predicted cat: 2306 (96.08%) | predicted dog: 72 (3.00%) | predicted unknown: 22 (0.92%)\n",
      "True dogs: 4990 | predicted dog: 4953 (99.26%) | predicted cat: 23 (0.46%) | predicted unknown: 14 (0.28%)\n",
      "\n",
      "Totals by predicted label:\n",
      "Predicted cats: 2329 (31.52%)\n",
      "Predicted dogs: 5025 (68.00%)\n",
      "Predicted unknown: 36 (0.49%)\n",
      "\n",
      "Key metrics (cats/dogs only truth):\n",
      "Overall accuracy (unknown counted as wrong): 98.23%\n",
      "Accepted rate (not unknown): 99.51%\n",
      "Accuracy among accepted only: 98.71%\n",
      "Balanced accuracy (avg cat+dog recall): 97.67%\n",
      "\n",
      "Per-class metrics:\n",
      "Cat precision: 99.01% | Cat recall: 96.08% | Cat F1: 97.53%\n",
      "Dog precision: 98.57% | Dog recall: 99.26% | Dog F1: 98.91%\n",
      "Macro F1: 98.22%\n",
      "\n",
      "Exact error counts:\n",
      "Cats predicted as dogs: 72\n",
      "Cats rejected as unknown: 22\n",
      "Dogs predicted as cats: 23\n",
      "Dogs rejected as unknown: 14\n",
      "Found 3650 files.\n",
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 265ms/step\n",
      "\n",
      "Places unknown holdout results:\n",
      "Threshold: 0.46\n",
      "Total images: 3650\n",
      "Predicted unknown rate: 99.12 %\n",
      "Predicted cat rate: 0.16 %\n",
      "Predicted dog rate: 0.71 %\n",
      "Found 3984 files.\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 272ms/step\n",
      "\n",
      "COCO unknown holdout results:\n",
      "Threshold: 0.46\n",
      "Total images: 3984\n",
      "Predicted unknown rate: 98.95 %\n",
      "Predicted cat rate: 0.23 %\n",
      "Predicted dog rate: 0.83 %\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# This cell assumes these already exist from earlier cells:\n",
    "# base_project_directory, image_height, image_width, batch_size, random_seed\n",
    "required_variable_names = [\"base_project_directory\", \"image_height\", \"image_width\", \"batch_size\", \"random_seed\"]\n",
    "missing_variable_names = [name for name in required_variable_names if name not in globals()]\n",
    "if missing_variable_names:\n",
    "    raise RuntimeError(\"Missing required variables: \" + \", \".join(missing_variable_names))\n",
    "\n",
    "\n",
    "class_names_in_order = [\"cats\", \"dogs\", \"unknown\"]\n",
    "unknown_class_index = 2\n",
    "\n",
    "datasets_test_directory = Path(base_project_directory) / \"Datasets\" / \"Test\"\n",
    "oxford_test_directory = datasets_test_directory / \"oxford_test\"\n",
    "unknown_test_directory = datasets_test_directory / \"unknown_test\"\n",
    "unknown_places_test_directory = unknown_test_directory / \"unknown_places\"\n",
    "unknown_coco_test_directory = unknown_test_directory / \"unknown_coco\"\n",
    "\n",
    "ai_model_directory = Path(base_project_directory) / \"AI Model\"\n",
    "saved_models_directory = globals().get(\"saved_models_directory\", ai_model_directory / \"models\")\n",
    "outputs_directory = globals().get(\"outputs_directory\", ai_model_directory / \"outputs\")\n",
    "\n",
    "final_model_file_path = saved_models_directory / \"cat_dog_unknown_classifier.keras\"\n",
    "frozen_threshold_file_path = outputs_directory / \"frozen_threshold.json\"\n",
    "\n",
    "\n",
    "def apply_unknown_threshold(probabilities: np.ndarray, confidence_threshold: float) -> np.ndarray:\n",
    "    probabilities = np.asarray(probabilities)\n",
    "\n",
    "    if probabilities.ndim != 2:\n",
    "        raise ValueError(f\"probabilities must be 2D (num_samples, num_classes). Got: {probabilities.shape}\")\n",
    "\n",
    "    maximum_probabilities = probabilities.max(axis=1)\n",
    "    predicted_indices = probabilities.argmax(axis=1).astype(int)\n",
    "\n",
    "    predicted_indices = np.where(\n",
    "        maximum_probabilities < confidence_threshold,\n",
    "        unknown_class_index,\n",
    "        predicted_indices,\n",
    "    )\n",
    "    return predicted_indices\n",
    "\n",
    "\n",
    "def load_frozen_threshold(threshold_file_path: Path) -> float:\n",
    "    if not threshold_file_path.exists():\n",
    "        raise RuntimeError(f\"Frozen threshold file not found: {threshold_file_path}\")\n",
    "\n",
    "    with open(threshold_file_path, \"r\", encoding=\"utf-8\") as threshold_file:\n",
    "        threshold_payload = json.load(threshold_file)\n",
    "\n",
    "    if \"chosen_threshold\" not in threshold_payload:\n",
    "        raise RuntimeError(f\"Expected 'chosen_threshold' key in: {threshold_file_path}\")\n",
    "\n",
    "    return float(threshold_payload[\"chosen_threshold\"])\n",
    "\n",
    "\n",
    "def build_scaled_labeled_dataset(directory_path: Path, class_names: list[str]) -> tf.data.Dataset:\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory=str(directory_path),\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"int\",\n",
    "        class_names=class_names,\n",
    "        image_size=(image_height, image_width),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    def scale_images(images, labels):\n",
    "        images = tf.cast(images, tf.float32) / 255.0\n",
    "        return images, labels\n",
    "\n",
    "    return dataset.map(scale_images, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "def build_scaled_unlabeled_dataset(directory_path: Path) -> tf.data.Dataset:\n",
    "    dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        directory=str(directory_path),\n",
    "        labels=None,\n",
    "        image_size=(image_height, image_width),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    def scale_images(images):\n",
    "        images = tf.cast(images, tf.float32) / 255.0\n",
    "        return images\n",
    "\n",
    "    return dataset.map(scale_images, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "def collect_true_labels(labeled_dataset: tf.data.Dataset) -> np.ndarray:\n",
    "    labels_batches = []\n",
    "    for _, labels in labeled_dataset:\n",
    "        labels_batches.append(labels.numpy())\n",
    "    return np.concatenate(labels_batches, axis=0).astype(int)\n",
    "\n",
    "\n",
    "def compute_oxford_metrics(true_labels: np.ndarray, predicted_labels: np.ndarray) -> dict:\n",
    "    true_labels = true_labels.astype(int)\n",
    "    predicted_labels = predicted_labels.astype(int)\n",
    "\n",
    "    cats_mask = true_labels == 0\n",
    "    dogs_mask = true_labels == 1\n",
    "    known_mask = cats_mask | dogs_mask\n",
    "\n",
    "    overall_accuracy = float(np.mean(predicted_labels == true_labels)) if len(true_labels) else 0.0\n",
    "    rejected_as_unknown_rate = float(np.mean(predicted_labels == unknown_class_index)) if len(true_labels) else 0.0\n",
    "\n",
    "    cat_recall = float(np.mean(predicted_labels[cats_mask] == 0)) if np.any(cats_mask) else 0.0\n",
    "    dog_recall = float(np.mean(predicted_labels[dogs_mask] == 1)) if np.any(dogs_mask) else 0.0\n",
    "\n",
    "    cats_rejected_as_unknown = float(np.mean(predicted_labels[cats_mask] == unknown_class_index)) if np.any(cats_mask) else 0.0\n",
    "    dogs_rejected_as_unknown = float(np.mean(predicted_labels[dogs_mask] == unknown_class_index)) if np.any(dogs_mask) else 0.0\n",
    "\n",
    "    known_accuracy = float(np.mean(predicted_labels[known_mask] == true_labels[known_mask])) if np.any(known_mask) else 0.0\n",
    "\n",
    "    return {\n",
    "        \"total_images\": int(len(true_labels)),\n",
    "        \"accuracy_unknown_counted_wrong\": overall_accuracy,\n",
    "        \"known_only_accuracy\": known_accuracy,\n",
    "        \"rejected_as_unknown_rate\": rejected_as_unknown_rate,\n",
    "        \"cat_recall\": cat_recall,\n",
    "        \"dog_recall\": dog_recall,\n",
    "        \"cats_rejected_as_unknown\": cats_rejected_as_unknown,\n",
    "        \"dogs_rejected_as_unknown\": dogs_rejected_as_unknown,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_unknown_test_metrics(predicted_labels: np.ndarray) -> dict:\n",
    "    predicted_labels = predicted_labels.astype(int)\n",
    "    total_images = int(len(predicted_labels))\n",
    "\n",
    "    if total_images == 0:\n",
    "        return {\n",
    "            \"total_images\": 0,\n",
    "            \"predicted_unknown_rate\": 0.0,\n",
    "            \"false_accept_rate_predicted_cat_or_dog\": 0.0,\n",
    "            \"predicted_cats_rate\": 0.0,\n",
    "            \"predicted_dogs_rate\": 0.0,\n",
    "        }\n",
    "\n",
    "    predicted_unknown_rate = float(np.mean(predicted_labels == unknown_class_index))\n",
    "    predicted_cats_rate = float(np.mean(predicted_labels == 0))\n",
    "    predicted_dogs_rate = float(np.mean(predicted_labels == 1))\n",
    "    false_accept_rate = float(np.mean((predicted_labels == 0) | (predicted_labels == 1)))\n",
    "\n",
    "    return {\n",
    "        \"total_images\": total_images,\n",
    "        \"predicted_unknown_rate\": predicted_unknown_rate,\n",
    "        \"false_accept_rate_predicted_cat_or_dog\": false_accept_rate,\n",
    "        \"predicted_cats_rate\": predicted_cats_rate,\n",
    "        \"predicted_dogs_rate\": predicted_dogs_rate,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_confusion_matrix_2x3(true_labels: np.ndarray, predicted_labels: np.ndarray) -> np.ndarray:\n",
    "    matrix = np.zeros((2, 3), dtype=int)\n",
    "\n",
    "    for true_value, predicted_value in zip(true_labels.tolist(), predicted_labels.tolist(), strict=False):\n",
    "        if true_value not in (0, 1):\n",
    "            continue\n",
    "        if predicted_value not in (0, 1, 2):\n",
    "            continue\n",
    "        matrix[true_value, predicted_value] += 1\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "if not final_model_file_path.exists():\n",
    "    raise RuntimeError(f\"Final model file not found: {final_model_file_path}\")\n",
    "\n",
    "chosen_threshold = load_frozen_threshold(frozen_threshold_file_path)\n",
    "print(f\"Using frozen threshold from validation: {chosen_threshold:.2f}\")\n",
    "\n",
    "model = tf.keras.models.load_model(final_model_file_path)\n",
    "\n",
    "\n",
    "# Oxford cats and dogs holdout\n",
    "oxford_dataset = build_scaled_labeled_dataset(\n",
    "    directory_path=oxford_test_directory,\n",
    "    class_names=[\"cats\", \"dogs\"],\n",
    ")\n",
    "oxford_true_labels = collect_true_labels(oxford_dataset)\n",
    "oxford_probabilities = model.predict(oxford_dataset, verbose=1)\n",
    "oxford_predicted_labels = apply_unknown_threshold(probabilities=oxford_probabilities, confidence_threshold=chosen_threshold)\n",
    "\n",
    "oxford_metrics = compute_oxford_metrics(true_labels=oxford_true_labels, predicted_labels=oxford_predicted_labels)\n",
    "confusion_matrix_2x3 = compute_confusion_matrix_2x3(\n",
    "    true_labels=oxford_true_labels,\n",
    "    predicted_labels=oxford_predicted_labels,\n",
    ")\n",
    "\n",
    "cats_total = int(np.sum(oxford_true_labels == 0))\n",
    "dogs_total = int(np.sum(oxford_true_labels == 1))\n",
    "total_images = int(len(oxford_true_labels))\n",
    "\n",
    "cats_predicted_as_cats = int(confusion_matrix_2x3[0, 0])\n",
    "cats_predicted_as_dogs = int(confusion_matrix_2x3[0, 1])\n",
    "cats_predicted_as_unknown = int(confusion_matrix_2x3[0, 2])\n",
    "dogs_predicted_as_cats = int(confusion_matrix_2x3[1, 0])\n",
    "dogs_predicted_as_dogs = int(confusion_matrix_2x3[1, 1])\n",
    "dogs_predicted_as_unknown = int(confusion_matrix_2x3[1, 2])\n",
    "\n",
    "predicted_cats_total = int(np.sum(oxford_predicted_labels == 0))\n",
    "predicted_dogs_total = int(np.sum(oxford_predicted_labels == 1))\n",
    "predicted_unknown_total = int(np.sum(oxford_predicted_labels == 2))\n",
    "\n",
    "accepted_count = predicted_cats_total + predicted_dogs_total\n",
    "accepted_rate = (accepted_count / total_images) if total_images else 0.0\n",
    "accuracy_among_accepted = (\n",
    "    (cats_predicted_as_cats + dogs_predicted_as_dogs) / accepted_count\n",
    "    if accepted_count\n",
    "    else 0.0\n",
    ")\n",
    "balanced_accuracy = (oxford_metrics[\"cat_recall\"] + oxford_metrics[\"dog_recall\"]) / 2.0\n",
    "\n",
    "cat_precision = (cats_predicted_as_cats / predicted_cats_total) if predicted_cats_total else 0.0\n",
    "dog_precision = (dogs_predicted_as_dogs / predicted_dogs_total) if predicted_dogs_total else 0.0\n",
    "cat_f1 = (\n",
    "    (2.0 * cat_precision * oxford_metrics[\"cat_recall\"]) / (cat_precision + oxford_metrics[\"cat_recall\"])\n",
    "    if (cat_precision + oxford_metrics[\"cat_recall\"]) > 0\n",
    "    else 0.0\n",
    ")\n",
    "dog_f1 = (\n",
    "    (2.0 * dog_precision * oxford_metrics[\"dog_recall\"]) / (dog_precision + oxford_metrics[\"dog_recall\"])\n",
    "    if (dog_precision + oxford_metrics[\"dog_recall\"]) > 0\n",
    "    else 0.0\n",
    ")\n",
    "macro_f1 = (cat_f1 + dog_f1) / 2.0\n",
    "\n",
    "print(\"\\nOxford holdout results (cats/dogs only):\")\n",
    "print(f\"Threshold: {chosen_threshold:.2f}\")\n",
    "print(f\"Total images: {total_images}\")\n",
    "print(f\"Accuracy (unknown counted as wrong): {oxford_metrics['accuracy_unknown_counted_wrong']*100:.2f} %\")\n",
    "print(f\"Rejected as unknown rate: {oxford_metrics['rejected_as_unknown_rate']*100:.2f} %\")\n",
    "print(f\"Cat recall: {oxford_metrics['cat_recall']*100:.2f} %\")\n",
    "print(f\"Dog recall: {oxford_metrics['dog_recall']*100:.2f} %\")\n",
    "print(f\"Cats rejected as unknown: {oxford_metrics['cats_rejected_as_unknown']*100:.2f} %\")\n",
    "print(f\"Dogs rejected as unknown: {oxford_metrics['dogs_rejected_as_unknown']*100:.2f} %\")\n",
    "\n",
    "print(\"\\nConfusion matrix (rows=true, cols=pred):\")\n",
    "print(\"                cats      dogs   unknown\")\n",
    "print(f\"true cats     {cats_predicted_as_cats:8d}  {cats_predicted_as_dogs:8d}  {cats_predicted_as_unknown:8d}\")\n",
    "print(f\"true dogs     {dogs_predicted_as_cats:8d}  {dogs_predicted_as_dogs:8d}  {dogs_predicted_as_unknown:8d}\")\n",
    "\n",
    "print(\"\\nBreakdown by true class:\")\n",
    "print(\n",
    "    f\"True cats: {cats_total} | predicted cat: {cats_predicted_as_cats} ({(cats_predicted_as_cats / cats_total * 100) if cats_total else 0.0:.2f}%) | \"\n",
    "    f\"predicted dog: {cats_predicted_as_dogs} ({(cats_predicted_as_dogs / cats_total * 100) if cats_total else 0.0:.2f}%) | \"\n",
    "    f\"predicted unknown: {cats_predicted_as_unknown} ({(cats_predicted_as_unknown / cats_total * 100) if cats_total else 0.0:.2f}%)\"\n",
    ")\n",
    "print(\n",
    "    f\"True dogs: {dogs_total} | predicted dog: {dogs_predicted_as_dogs} ({(dogs_predicted_as_dogs / dogs_total * 100) if dogs_total else 0.0:.2f}%) | \"\n",
    "    f\"predicted cat: {dogs_predicted_as_cats} ({(dogs_predicted_as_cats / dogs_total * 100) if dogs_total else 0.0:.2f}%) | \"\n",
    "    f\"predicted unknown: {dogs_predicted_as_unknown} ({(dogs_predicted_as_unknown / dogs_total * 100) if dogs_total else 0.0:.2f}%)\"\n",
    ")\n",
    "\n",
    "print(\"\\nTotals by predicted label:\")\n",
    "print(f\"Predicted cats: {predicted_cats_total} ({(predicted_cats_total / total_images * 100) if total_images else 0.0:.2f}%)\")\n",
    "print(f\"Predicted dogs: {predicted_dogs_total} ({(predicted_dogs_total / total_images * 100) if total_images else 0.0:.2f}%)\")\n",
    "print(f\"Predicted unknown: {predicted_unknown_total} ({(predicted_unknown_total / total_images * 100) if total_images else 0.0:.2f}%)\")\n",
    "\n",
    "print(\"\\nKey metrics (cats/dogs only truth):\")\n",
    "print(f\"Overall accuracy (unknown counted as wrong): {oxford_metrics['accuracy_unknown_counted_wrong']*100:.2f}%\")\n",
    "print(f\"Accepted rate (not unknown): {accepted_rate*100:.2f}%\")\n",
    "print(f\"Accuracy among accepted only: {accuracy_among_accepted*100:.2f}%\")\n",
    "print(f\"Balanced accuracy (avg cat+dog recall): {balanced_accuracy*100:.2f}%\")\n",
    "\n",
    "print(\"\\nPer-class metrics:\")\n",
    "print(f\"Cat precision: {cat_precision*100:.2f}% | Cat recall: {oxford_metrics['cat_recall']*100:.2f}% | Cat F1: {cat_f1*100:.2f}%\")\n",
    "print(f\"Dog precision: {dog_precision*100:.2f}% | Dog recall: {oxford_metrics['dog_recall']*100:.2f}% | Dog F1: {dog_f1*100:.2f}%\")\n",
    "print(f\"Macro F1: {macro_f1*100:.2f}%\")\n",
    "\n",
    "print(\"\\nExact error counts:\")\n",
    "print(f\"Cats predicted as dogs: {cats_predicted_as_dogs}\")\n",
    "print(f\"Cats rejected as unknown: {cats_predicted_as_unknown}\")\n",
    "print(f\"Dogs predicted as cats: {dogs_predicted_as_cats}\")\n",
    "print(f\"Dogs rejected as unknown: {dogs_predicted_as_unknown}\")\n",
    "\n",
    "\n",
    "# Places unknown holdout\n",
    "unknown_places_dataset = build_scaled_unlabeled_dataset(unknown_places_test_directory)\n",
    "unknown_places_probabilities = model.predict(unknown_places_dataset, verbose=1)\n",
    "unknown_places_predicted_labels = apply_unknown_threshold(\n",
    "    probabilities=unknown_places_probabilities,\n",
    "    confidence_threshold=chosen_threshold,\n",
    ")\n",
    "unknown_places_metrics = compute_unknown_test_metrics(unknown_places_predicted_labels)\n",
    "\n",
    "print(\"\\nPlaces unknown holdout results:\")\n",
    "print(f\"Threshold: {chosen_threshold:.2f}\")\n",
    "print(f\"Total images: {unknown_places_metrics['total_images']}\")\n",
    "print(f\"Predicted unknown rate: {unknown_places_metrics['predicted_unknown_rate']*100:.2f} %\")\n",
    "print(f\"Predicted cat rate: {unknown_places_metrics['predicted_cats_rate']*100:.2f} %\")\n",
    "print(f\"Predicted dog rate: {unknown_places_metrics['predicted_dogs_rate']*100:.2f} %\")\n",
    "\n",
    "\n",
    "# COCO unknown holdout\n",
    "unknown_coco_dataset = build_scaled_unlabeled_dataset(unknown_coco_test_directory)\n",
    "unknown_coco_probabilities = model.predict(unknown_coco_dataset, verbose=1)\n",
    "unknown_coco_predicted_labels = apply_unknown_threshold(\n",
    "    probabilities=unknown_coco_probabilities,\n",
    "    confidence_threshold=chosen_threshold,\n",
    ")\n",
    "unknown_coco_metrics = compute_unknown_test_metrics(unknown_coco_predicted_labels)\n",
    "\n",
    "print(\"\\nCOCO unknown holdout results:\")\n",
    "print(f\"Threshold: {chosen_threshold:.2f}\")\n",
    "print(f\"Total images: {unknown_coco_metrics['total_images']}\")\n",
    "print(f\"Predicted unknown rate: {unknown_coco_metrics['predicted_unknown_rate']*100:.2f} %\")\n",
    "print(f\"Predicted cat rate: {unknown_coco_metrics['predicted_cats_rate']*100:.2f} %\")\n",
    "print(f\"Predicted dog rate: {unknown_coco_metrics['predicted_dogs_rate']*100:.2f} %\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
